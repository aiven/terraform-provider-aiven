// Code generated by internal/schemautil/userconfig/userconfig_test.go; DO NOT EDIT.

package dist

import (
	schemautil "github.com/aiven/terraform-provider-aiven/internal/schemautil"
	schema "github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
)

// ServiceTypeCassandra is a generated function returning the schema of the cassandra ServiceType.
func ServiceTypeCassandra() *schema.Schema {
	s := map[string]*schema.Schema{
		"additional_backup_regions": {
			Description: "Additional Cloud Regions for Backup Replication",
			Elem:        &schema.Schema{Type: schema.TypeString},
			MaxItems:    1,
			Optional:    true,
			Type:        schema.TypeList,
		},
		"cassandra": {
			Description: "cassandra configuration values",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"batch_size_fail_threshold_in_kb": {
					Description: "Fail any multiple-partition batch exceeding this value. 50kb (10x warn threshold) by default.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"batch_size_warn_threshold_in_kb": {
					Description: "Log a warning message on any multiple-partition batch size exceeding this value.5kb per batch by default.Caution should be taken on increasing the size of this thresholdas it can lead to node instability.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"datacenter": {
					Description: "Name of the datacenter to which nodes of this service belong. Can be set only when creating the service.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"batch_size_fail_threshold_in_kb": {
					Description: "Fail any multiple-partition batch exceeding this value. 50kb (10x warn threshold) by default.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"batch_size_warn_threshold_in_kb": {
					Description: "Log a warning message on any multiple-partition batch size exceeding this value.5kb per batch by default.Caution should be taken on increasing the size of this thresholdas it can lead to node instability.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"datacenter": {
					Description: "Name of the datacenter to which nodes of this service belong. Can be set only when creating the service.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"cassandra_version": {
			Description: "Cassandra major version",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"ip_filter": {
			Description:      "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			DiffSuppressFunc: schemautil.IPFilterArrayDiffSuppressFunc,
			Elem: &schema.Schema{
				DiffSuppressFunc: schemautil.IPFilterValueDiffSuppressFunc,
				Type:             schema.TypeString,
			},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter_object": {
			Description: "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"description": {
					Description: "Description for IP filter list entry",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"network": {
					Description: "CIDR address block",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"migrate_sstableloader": {
			Description: "Sets the service into migration mode enabling the sstableloader utility to be used to upload Cassandra data files. Available only on service create.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"private_access": {
			Description: "Allow access to selected service ports from private networks",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{"prometheus": {
				Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
				Optional:    true,
				Type:        schema.TypeString,
			}}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{"prometheus": {
				Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
				Optional:    true,
				Type:        schema.TypeString,
			}}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"project_to_fork_from": {
			Description: "Name of another project to fork a service from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"public_access": {
			Description: "Allow access to selected service ports from the public Internet",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{"prometheus": {
				Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network",
				Optional:    true,
				Type:        schema.TypeString,
			}}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{"prometheus": {
				Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network",
				Optional:    true,
				Type:        schema.TypeString,
			}}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"service_to_fork_from": {
			Description: "Name of another service to fork from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"service_to_join_with": {
			Description: "When bootstrapping, instead of creating a new Cassandra cluster try to join an existing one from another service. Can only be set on service creation.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"static_ips": {
			Description: "Use static public IP addresses",
			Optional:    true,
			Type:        schema.TypeString,
		},
	}

	return &schema.Schema{
		Description:      "Cassandra user configurable settings",
		DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(s),
		Elem:             &schema.Resource{Schema: s},
		MaxItems:         1,
		Optional:         true,
		Type:             schema.TypeList,
	}
}

// ServiceTypeClickhouse is a generated function returning the schema of the clickhouse ServiceType.
func ServiceTypeClickhouse() *schema.Schema {
	s := map[string]*schema.Schema{
		"additional_backup_regions": {
			Description: "Additional Cloud Regions for Backup Replication",
			Elem:        &schema.Schema{Type: schema.TypeString},
			MaxItems:    1,
			Optional:    true,
			Type:        schema.TypeList,
		},
		"ip_filter": {
			Description:      "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			DiffSuppressFunc: schemautil.IPFilterArrayDiffSuppressFunc,
			Elem: &schema.Schema{
				DiffSuppressFunc: schemautil.IPFilterValueDiffSuppressFunc,
				Type:             schema.TypeString,
			},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter_object": {
			Description: "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"description": {
					Description: "Description for IP filter list entry",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"network": {
					Description: "CIDR address block",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"project_to_fork_from": {
			Description: "Name of another project to fork a service from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"service_to_fork_from": {
			Description: "Name of another service to fork from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
	}

	return &schema.Schema{
		Description:      "Clickhouse user configurable settings",
		DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(s),
		Elem:             &schema.Resource{Schema: s},
		MaxItems:         1,
		Optional:         true,
		Type:             schema.TypeList,
	}
}

// ServiceTypeElasticsearch is a generated function returning the schema of the elasticsearch ServiceType.
func ServiceTypeElasticsearch() *schema.Schema {
	s := map[string]*schema.Schema{
		"additional_backup_regions": {
			Description: "Additional Cloud Regions for Backup Replication",
			Elem:        &schema.Schema{Type: schema.TypeString},
			MaxItems:    1,
			Optional:    true,
			Type:        schema.TypeList,
		},
		"custom_domain": {
			Description: "Serve the web frontend using a custom CNAME pointing to the Aiven DNS name",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"disable_replication_factor_adjustment": {
			Deprecated: "DEPRECATED: Disable automatic replication factor adjustment for multi-node services. By default, Aiven ensures all indexes are replicated at least to two nodes. Note: Due to potential data loss in case of losing a service node, this setting can no longer be activated.",
			Optional:   true,
			Type:       schema.TypeString,
		},
		"elasticsearch": {
			Description: "Elasticsearch settings",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"action_auto_create_index_enabled": {
					Description: "Explicitly allow or block automatic creation of indices. Defaults to true",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"action_destructive_requires_name": {
					Description: "Require explicit index names when deleting",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"cluster_max_shards_per_node": {
					Description: "Controls the number of shards allowed in the cluster per data node",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"cluster_routing_allocation_node_concurrent_recoveries": {
					Description: "How many concurrent incoming/outgoing shard recoveries (normally replicas) are allowed to happen on a node. Defaults to 2.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"email_sender_name": {
					Description: "This should be identical to the Sender name defined in Opensearch dashboards",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"email_sender_password": {
					Description: "Sender email password for Opensearch alerts to authenticate with SMTP server",
					Optional:    true,
					Sensitive:   true,
					Type:        schema.TypeString,
				},
				"email_sender_username": {
					Description: "Sender email address for Opensearch alerts",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"http_max_content_length": {
					Description: "Maximum content length for HTTP requests to the Elasticsearch HTTP API, in bytes.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"http_max_header_size": {
					Description: "The max size of allowed headers, in bytes",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"http_max_initial_line_length": {
					Description: "The max length of an HTTP URL, in bytes",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_fielddata_cache_size": {
					Description: "Relative amount. Maximum amount of heap memory used for field data cache. This is an expert setting; decreasing the value too much will increase overhead of loading field data; too much memory used for field data cache will decrease amount of heap available for other operations.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_memory_index_buffer_size": {
					Description: "Percentage value. Default is 10%. Total amount of heap used for indexing buffer, before writing segments to disk. This is an expert setting. Too low value will slow down indexing; too high value will increase indexing performance but causes performance issues for query performance.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_queries_cache_size": {
					Description: "Percentage value. Default is 10%. Maximum amount of heap used for query cache. This is an expert setting. Too low value will decrease query performance and increase performance for other operations; too high value will cause issues with other Elasticsearch functionality.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_query_bool_max_clause_count": {
					Description: "Maximum number of clauses Lucene BooleanQuery can have. The default value (1024) is relatively high, and increasing it may cause performance issues. Investigate other approaches first before increasing this value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_recovery_max_bytes_per_sec": {
					Description: "Limits total inbound and outbound recovery traffic for each node. Applies to both peer recoveries as well as snapshot recoveries (i.e., restores from a snapshot). Defaults to 40mb",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_recovery_max_concurrent_file_chunks": {
					Description: "Number of file chunks sent in parallel for each recovery. Defaults to 2.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"override_main_response_version": {
					Description: "Compatibility mode sets OpenSearch to report its version as 7.10 so clients continue to work. Default is false",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"reindex_remote_whitelist": {
					Description: "Whitelisted addresses for reindexing. Changing this value will cause all Elasticsearch instances to restart.",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    32,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"script_max_compilations_rate": {
					Description: "Script compilation circuit breaker limits the number of inline script compilations within a period of time. Default is use-context",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"search_max_buckets": {
					Description: "Maximum number of aggregation buckets allowed in a single response. Elasticsearch default value is used when this is not defined.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_analyze_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_analyze_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_force_merge_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_get_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_get_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_search_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_search_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_search_throttled_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_search_throttled_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_write_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_write_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"action_auto_create_index_enabled": {
					Description: "Explicitly allow or block automatic creation of indices. Defaults to true",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"action_destructive_requires_name": {
					Description: "Require explicit index names when deleting",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"cluster_max_shards_per_node": {
					Description: "Controls the number of shards allowed in the cluster per data node",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"cluster_routing_allocation_node_concurrent_recoveries": {
					Description: "How many concurrent incoming/outgoing shard recoveries (normally replicas) are allowed to happen on a node. Defaults to 2.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"email_sender_name": {
					Description: "This should be identical to the Sender name defined in Opensearch dashboards",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"email_sender_password": {
					Description: "Sender email password for Opensearch alerts to authenticate with SMTP server",
					Optional:    true,
					Sensitive:   true,
					Type:        schema.TypeString,
				},
				"email_sender_username": {
					Description: "Sender email address for Opensearch alerts",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"http_max_content_length": {
					Description: "Maximum content length for HTTP requests to the Elasticsearch HTTP API, in bytes.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"http_max_header_size": {
					Description: "The max size of allowed headers, in bytes",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"http_max_initial_line_length": {
					Description: "The max length of an HTTP URL, in bytes",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_fielddata_cache_size": {
					Description: "Relative amount. Maximum amount of heap memory used for field data cache. This is an expert setting; decreasing the value too much will increase overhead of loading field data; too much memory used for field data cache will decrease amount of heap available for other operations.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_memory_index_buffer_size": {
					Description: "Percentage value. Default is 10%. Total amount of heap used for indexing buffer, before writing segments to disk. This is an expert setting. Too low value will slow down indexing; too high value will increase indexing performance but causes performance issues for query performance.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_queries_cache_size": {
					Description: "Percentage value. Default is 10%. Maximum amount of heap used for query cache. This is an expert setting. Too low value will decrease query performance and increase performance for other operations; too high value will cause issues with other Elasticsearch functionality.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_query_bool_max_clause_count": {
					Description: "Maximum number of clauses Lucene BooleanQuery can have. The default value (1024) is relatively high, and increasing it may cause performance issues. Investigate other approaches first before increasing this value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_recovery_max_bytes_per_sec": {
					Description: "Limits total inbound and outbound recovery traffic for each node. Applies to both peer recoveries as well as snapshot recoveries (i.e., restores from a snapshot). Defaults to 40mb",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_recovery_max_concurrent_file_chunks": {
					Description: "Number of file chunks sent in parallel for each recovery. Defaults to 2.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"override_main_response_version": {
					Description: "Compatibility mode sets OpenSearch to report its version as 7.10 so clients continue to work. Default is false",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"reindex_remote_whitelist": {
					Description: "Whitelisted addresses for reindexing. Changing this value will cause all Elasticsearch instances to restart.",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    32,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"script_max_compilations_rate": {
					Description: "Script compilation circuit breaker limits the number of inline script compilations within a period of time. Default is use-context",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"search_max_buckets": {
					Description: "Maximum number of aggregation buckets allowed in a single response. Elasticsearch default value is used when this is not defined.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_analyze_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_analyze_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_force_merge_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_get_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_get_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_search_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_search_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_search_throttled_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_search_throttled_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_write_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_write_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"elasticsearch_version": {
			Description: "Elasticsearch major version",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"index_patterns": {
			Description: "Index patterns",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"max_index_count": {
					Description: "Maximum number of indexes to keep",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"pattern": {
					Description: "fnmatch pattern",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"sorting_algorithm": {
					Description: "Deletion sorting algorithm",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 512,
			Optional: true,
			Type:     schema.TypeList,
		},
		"index_template": {
			Description: "Template settings for all new indexes",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"mapping_nested_objects_limit": {
					Description: "The maximum number of nested JSON objects that a single document can contain across all nested types. This limit helps to prevent out of memory errors when a document contains too many nested objects. Default is 10000.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"number_of_replicas": {
					Description: "The number of replicas each primary shard has.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"number_of_shards": {
					Description: "The number of primary shards that an index should have.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"mapping_nested_objects_limit": {
					Description: "The maximum number of nested JSON objects that a single document can contain across all nested types. This limit helps to prevent out of memory errors when a document contains too many nested objects. Default is 10000.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"number_of_replicas": {
					Description: "The number of replicas each primary shard has.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"number_of_shards": {
					Description: "The number of primary shards that an index should have.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter": {
			Description:      "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			DiffSuppressFunc: schemautil.IPFilterArrayDiffSuppressFunc,
			Elem: &schema.Schema{
				DiffSuppressFunc: schemautil.IPFilterValueDiffSuppressFunc,
				Type:             schema.TypeString,
			},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter_object": {
			Description: "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"description": {
					Description: "Description for IP filter list entry",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"network": {
					Description: "CIDR address block",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"keep_index_refresh_interval": {
			Description: "Aiven automation resets index.refresh_interval to default value for every index to be sure that indices are always visible to search. If it doesn't fit your case, you can disable this by setting up this flag to true.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"kibana": {
			Description: "Kibana settings",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"elasticsearch_request_timeout": {
					Description: "Timeout in milliseconds for requests made by Kibana towards Elasticsearch",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"enabled": {
					Description: "Enable or disable Kibana",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_old_space_size": {
					Description: "Limits the maximum amount of memory (in MiB) the Kibana process can use. This sets the max_old_space_size option of the nodejs running the Kibana. Note: the memory reserved by Kibana is not available for Elasticsearch.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"elasticsearch_request_timeout": {
					Description: "Timeout in milliseconds for requests made by Kibana towards Elasticsearch",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"enabled": {
					Description: "Enable or disable Kibana",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_old_space_size": {
					Description: "Limits the maximum amount of memory (in MiB) the Kibana process can use. This sets the max_old_space_size option of the nodejs running the Kibana. Note: the memory reserved by Kibana is not available for Elasticsearch.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"max_index_count": {
			Deprecated: "DEPRECATED: use index_patterns instead",
			Optional:   true,
			Type:       schema.TypeString,
		},
		"opensearch_version": {
			Description: "OpenSearch major version",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"private_access": {
			Description: "Allow access to selected service ports from private networks",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"elasticsearch": {
					Description: "Allow clients to connect to elasticsearch with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kibana": {
					Description: "Allow clients to connect to kibana with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"elasticsearch": {
					Description: "Allow clients to connect to elasticsearch with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kibana": {
					Description: "Allow clients to connect to kibana with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"privatelink_access": {
			Description: "Allow access to selected service components through Privatelink",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"elasticsearch": {
					Description: "Enable elasticsearch",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kibana": {
					Description: "Enable kibana",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Enable prometheus",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"elasticsearch": {
					Description: "Enable elasticsearch",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kibana": {
					Description: "Enable kibana",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Enable prometheus",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"project_to_fork_from": {
			Description: "Name of another project to fork a service from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"public_access": {
			Description: "Allow access to selected service ports from the public Internet",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"elasticsearch": {
					Description: "Allow clients to connect to elasticsearch from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kibana": {
					Description: "Allow clients to connect to kibana from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"elasticsearch": {
					Description: "Allow clients to connect to elasticsearch from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kibana": {
					Description: "Allow clients to connect to kibana from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"recovery_basebackup_name": {
			Description: "Name of the basebackup to restore in forked service",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"service_to_fork_from": {
			Description: "Name of another service to fork from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"static_ips": {
			Description: "Use static public IP addresses",
			Optional:    true,
			Type:        schema.TypeString,
		},
	}

	return &schema.Schema{
		Description:      "Elasticsearch user configurable settings",
		DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(s),
		Elem:             &schema.Resource{Schema: s},
		MaxItems:         1,
		Optional:         true,
		Type:             schema.TypeList,
	}
}

// ServiceTypeFlink is a generated function returning the schema of the flink ServiceType.
func ServiceTypeFlink() *schema.Schema {
	s := map[string]*schema.Schema{
		"additional_backup_regions": {
			Description: "Additional Cloud Regions for Backup Replication",
			Elem:        &schema.Schema{Type: schema.TypeString},
			MaxItems:    1,
			Optional:    true,
			Type:        schema.TypeList,
		},
		"execution_checkpointing_interval_ms": {
			Description: "Checkpointing is Flink’s primary fault-tolerance mechanism, wherein a snapshot of your job’s state persisted periodically to some durable location. In the case of failure, Flink will restart from the most recent checkpoint and resume processing. A jobs checkpoint interval configures how often Flink will take these snapshots.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"execution_checkpointing_timeout_ms": {
			Description: "The time after which a checkpoint-in-progress is aborted, if it did not complete by then.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"flink_version": {
			Description: "Flink major version",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"ip_filter": {
			Description:      "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			DiffSuppressFunc: schemautil.IPFilterArrayDiffSuppressFunc,
			Elem: &schema.Schema{
				DiffSuppressFunc: schemautil.IPFilterValueDiffSuppressFunc,
				Type:             schema.TypeString,
			},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter_object": {
			Description: "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"description": {
					Description: "Description for IP filter list entry",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"network": {
					Description: "CIDR address block",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"number_of_task_slots": {
			Description: "Task slots per node. For a 3 node plan, total number of task slots is 3x this value",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"parallelism_default": {
			Description: "How many parallel task slots each new job is assigned. Unless you understand how Flink parallel dataflows work, please leave this at 1. Please do not set this value higher than (total number of nodes x number_of_task_slots), or every new job created will fail.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"privatelink_access": {
			Description: "Allow access to selected service components through Privatelink",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"flink": {
					Description: "Enable flink",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Enable prometheus",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"flink": {
					Description: "Enable flink",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Enable prometheus",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"restart_strategy": {
			Description: "failure-rate (default): Restarts the job after failure, but when failure rate (failures per time interval) is exceeded, the job eventually fails. Restart strategy waits a fixed amount of time between attempts.fixed-delay: Attempts to restart the job a given number of times before it fails. Restart strategy waits a fixed amount of time between attempts. exponential-delay: Attempts to restart the job infinitely, with increasing delay up to the maximum delay. The job never fails. none: The job fails directly and no restart is attempted.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"restart_strategy_delay_sec": {
			Description: "Delay between two consecutive restart attempts if restart-strategy has been set to fixed-delay or failure-rate. Delaying the retries can be helpful when the program interacts with external systems where for example connections or pending transactions should reach a timeout before re-execution is attempted.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"restart_strategy_failure_rate_interval_min": {
			Description: "Time interval for measuring failure rate if restart-strategy has been set to failure-rate. Specified in minutes.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"restart_strategy_max_failures": {
			Description: "The number of times that Flink retries the execution before the job is declared as failed if restart-strategy has been set to fixed-delay or failure-rate.",
			Optional:    true,
			Type:        schema.TypeString,
		},
	}

	return &schema.Schema{
		Description:      "Flink user configurable settings",
		DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(s),
		Elem:             &schema.Resource{Schema: s},
		MaxItems:         1,
		Optional:         true,
		Type:             schema.TypeList,
	}
}

// ServiceTypeGrafana is a generated function returning the schema of the grafana ServiceType.
func ServiceTypeGrafana() *schema.Schema {
	s := map[string]*schema.Schema{
		"additional_backup_regions": {
			Description: "Additional Cloud Regions for Backup Replication",
			Elem:        &schema.Schema{Type: schema.TypeString},
			MaxItems:    1,
			Optional:    true,
			Type:        schema.TypeList,
		},
		"alerting_enabled": {
			Description: "Enable or disable Grafana alerting functionality",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"alerting_error_or_timeout": {
			Description: "Default error or timeout setting for new alerting rules",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"alerting_max_annotations_to_keep": {
			Description: "Max number of alert annotations that Grafana stores. 0 (default) keeps all alert annotations.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"alerting_nodata_or_nullvalues": {
			Description: "Default value for 'no data or null values' for new alerting rules",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"allow_embedding": {
			Description: "Allow embedding Grafana dashboards with iframe/frame/object/embed tags. Disabled by default to limit impact of clickjacking",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"auth_azuread": {
			Description: "Azure AD OAuth integration",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"allow_sign_up": {
					Description: "Automatically sign-up users on successful sign-in",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"allowed_domains": {
					Description: "Allowed domains",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    50,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"allowed_groups": {
					Description: "Require users to belong to one of given groups",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    50,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"auth_url": {
					Description: "Authorization URL",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"client_id": {
					Description: "Client ID from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"client_secret": {
					Description: "Client secret from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"token_url": {
					Description: "Token URL",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"allow_sign_up": {
					Description: "Automatically sign-up users on successful sign-in",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"allowed_domains": {
					Description: "Allowed domains",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    50,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"allowed_groups": {
					Description: "Require users to belong to one of given groups",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    50,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"auth_url": {
					Description: "Authorization URL",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"client_id": {
					Description: "Client ID from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"client_secret": {
					Description: "Client secret from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"token_url": {
					Description: "Token URL",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"auth_basic_enabled": {
			Description: "Enable or disable basic authentication form, used by Grafana built-in login",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"auth_generic_oauth": {
			Description: "Generic OAuth integration",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"allow_sign_up": {
					Description: "Automatically sign-up users on successful sign-in",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"allowed_domains": {
					Description: "Allowed domains",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    50,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"allowed_organizations": {
					Description: "Require user to be member of one of the listed organizations",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    50,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"api_url": {
					Description: "API URL",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"auth_url": {
					Description: "Authorization URL",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"client_id": {
					Description: "Client ID from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"client_secret": {
					Description: "Client secret from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"name": {
					Description: "Name of the OAuth integration",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"scopes": {
					Description: "OAuth scopes",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    50,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"token_url": {
					Description: "Token URL",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"allow_sign_up": {
					Description: "Automatically sign-up users on successful sign-in",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"allowed_domains": {
					Description: "Allowed domains",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    50,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"allowed_organizations": {
					Description: "Require user to be member of one of the listed organizations",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    50,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"api_url": {
					Description: "API URL",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"auth_url": {
					Description: "Authorization URL",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"client_id": {
					Description: "Client ID from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"client_secret": {
					Description: "Client secret from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"name": {
					Description: "Name of the OAuth integration",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"scopes": {
					Description: "OAuth scopes",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    50,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"token_url": {
					Description: "Token URL",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"auth_github": {
			Description: "Github Auth integration",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"allow_sign_up": {
					Description: "Automatically sign-up users on successful sign-in",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"allowed_organizations": {
					Description: "Require users to belong to one of given organizations",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    50,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"client_id": {
					Description: "Client ID from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"client_secret": {
					Description: "Client secret from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"team_ids": {
					Description: "Require users to belong to one of given team IDs",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    50,
					Optional:    true,
					Type:        schema.TypeList,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"allow_sign_up": {
					Description: "Automatically sign-up users on successful sign-in",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"allowed_organizations": {
					Description: "Require users to belong to one of given organizations",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    50,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"client_id": {
					Description: "Client ID from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"client_secret": {
					Description: "Client secret from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"team_ids": {
					Description: "Require users to belong to one of given team IDs",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    50,
					Optional:    true,
					Type:        schema.TypeList,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"auth_gitlab": {
			Description: "GitLab Auth integration",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"allow_sign_up": {
					Description: "Automatically sign-up users on successful sign-in",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"allowed_groups": {
					Description: "Require users to belong to one of given groups",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    50,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"api_url": {
					Description: "API URL. This only needs to be set when using self hosted GitLab",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"auth_url": {
					Description: "Authorization URL. This only needs to be set when using self hosted GitLab",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"client_id": {
					Description: "Client ID from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"client_secret": {
					Description: "Client secret from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"token_url": {
					Description: "Token URL. This only needs to be set when using self hosted GitLab",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"allow_sign_up": {
					Description: "Automatically sign-up users on successful sign-in",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"allowed_groups": {
					Description: "Require users to belong to one of given groups",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    50,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"api_url": {
					Description: "API URL. This only needs to be set when using self hosted GitLab",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"auth_url": {
					Description: "Authorization URL. This only needs to be set when using self hosted GitLab",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"client_id": {
					Description: "Client ID from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"client_secret": {
					Description: "Client secret from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"token_url": {
					Description: "Token URL. This only needs to be set when using self hosted GitLab",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"auth_google": {
			Description: "Google Auth integration",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"allow_sign_up": {
					Description: "Automatically sign-up users on successful sign-in",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"allowed_domains": {
					Description: "Domains allowed to sign-in to this Grafana",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    64,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"client_id": {
					Description: "Client ID from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"client_secret": {
					Description: "Client secret from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"allow_sign_up": {
					Description: "Automatically sign-up users on successful sign-in",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"allowed_domains": {
					Description: "Domains allowed to sign-in to this Grafana",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    64,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"client_id": {
					Description: "Client ID from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"client_secret": {
					Description: "Client secret from provider",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"cookie_samesite": {
			Description: "Cookie SameSite attribute: 'strict' prevents sending cookie for cross-site requests, effectively disabling direct linking from other sites to Grafana. 'lax' is the default value.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"custom_domain": {
			Description: "Serve the web frontend using a custom CNAME pointing to the Aiven DNS name",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"dashboard_previews_enabled": {
			Description: "This feature is new in Grafana 9 and is quite resource intensive. It may cause low-end plans to work more slowly while the dashboard previews are rendering.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"dashboards_min_refresh_interval": {
			Description: "Signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s, 1h",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"dashboards_versions_to_keep": {
			Description: "Dashboard versions to keep per dashboard",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"dataproxy_send_user_header": {
			Description: "Send 'X-Grafana-User' header to data source",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"dataproxy_timeout": {
			Description: "Timeout for data proxy requests in seconds",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"date_formats": {
			Description: "Grafana date format specifications",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"default_timezone": {
					Description: "Default time zone for user preferences. Value 'browser' uses browser local time zone.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"full_date": {
					Description: "Moment.js style format string for cases where full date is shown",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"interval_day": {
					Description: "Moment.js style format string used when a time requiring day accuracy is shown",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"interval_hour": {
					Description: "Moment.js style format string used when a time requiring hour accuracy is shown",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"interval_minute": {
					Description: "Moment.js style format string used when a time requiring minute accuracy is shown",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"interval_month": {
					Description: "Moment.js style format string used when a time requiring month accuracy is shown",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"interval_second": {
					Description: "Moment.js style format string used when a time requiring second accuracy is shown",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"interval_year": {
					Description: "Moment.js style format string used when a time requiring year accuracy is shown",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"default_timezone": {
					Description: "Default time zone for user preferences. Value 'browser' uses browser local time zone.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"full_date": {
					Description: "Moment.js style format string for cases where full date is shown",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"interval_day": {
					Description: "Moment.js style format string used when a time requiring day accuracy is shown",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"interval_hour": {
					Description: "Moment.js style format string used when a time requiring hour accuracy is shown",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"interval_minute": {
					Description: "Moment.js style format string used when a time requiring minute accuracy is shown",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"interval_month": {
					Description: "Moment.js style format string used when a time requiring month accuracy is shown",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"interval_second": {
					Description: "Moment.js style format string used when a time requiring second accuracy is shown",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"interval_year": {
					Description: "Moment.js style format string used when a time requiring year accuracy is shown",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"disable_gravatar": {
			Description: "Set to true to disable gravatar. Defaults to false (gravatar is enabled)",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"editors_can_admin": {
			Description: "Editors can manage folders, teams and dashboards created by them",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"external_image_storage": {
			Description: "External image store settings",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"access_key": {
					Description: "S3 access key. Requires permissions to the S3 bucket for the s3:PutObject and s3:PutObjectAcl actions",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"bucket_url": {
					Description: "Bucket URL for S3",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"provider": {
					Description: "Provider type",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"secret_key": {
					Description: "S3 secret key",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"access_key": {
					Description: "S3 access key. Requires permissions to the S3 bucket for the s3:PutObject and s3:PutObjectAcl actions",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"bucket_url": {
					Description: "Bucket URL for S3",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"provider": {
					Description: "Provider type",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"secret_key": {
					Description: "S3 secret key",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"google_analytics_ua_id": {
			Description: "Google Analytics ID",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"ip_filter": {
			Description:      "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			DiffSuppressFunc: schemautil.IPFilterArrayDiffSuppressFunc,
			Elem: &schema.Schema{
				DiffSuppressFunc: schemautil.IPFilterValueDiffSuppressFunc,
				Type:             schema.TypeString,
			},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter_object": {
			Description: "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"description": {
					Description: "Description for IP filter list entry",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"network": {
					Description: "CIDR address block",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"metrics_enabled": {
			Description: "Enable Grafana /metrics endpoint",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"private_access": {
			Description: "Allow access to selected service ports from private networks",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{"grafana": {
				Description: "Allow clients to connect to grafana with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
				Optional:    true,
				Type:        schema.TypeString,
			}}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{"grafana": {
				Description: "Allow clients to connect to grafana with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
				Optional:    true,
				Type:        schema.TypeString,
			}}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"privatelink_access": {
			Description: "Allow access to selected service components through Privatelink",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{"grafana": {
				Description: "Enable grafana",
				Optional:    true,
				Type:        schema.TypeString,
			}}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{"grafana": {
				Description: "Enable grafana",
				Optional:    true,
				Type:        schema.TypeString,
			}}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"project_to_fork_from": {
			Description: "Name of another project to fork a service from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"public_access": {
			Description: "Allow access to selected service ports from the public Internet",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{"grafana": {
				Description: "Allow clients to connect to grafana from the public internet for service nodes that are in a project VPC or another type of private network",
				Optional:    true,
				Type:        schema.TypeString,
			}}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{"grafana": {
				Description: "Allow clients to connect to grafana from the public internet for service nodes that are in a project VPC or another type of private network",
				Optional:    true,
				Type:        schema.TypeString,
			}}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"recovery_basebackup_name": {
			Description: "Name of the basebackup to restore in forked service",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"service_to_fork_from": {
			Description: "Name of another service to fork from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"smtp_server": {
			Description: "SMTP server settings",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"from_address": {
					Description: "Address used for sending emails",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"from_name": {
					Description: "Name used in outgoing emails, defaults to Grafana",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"host": {
					Description: "Server hostname or IP",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"password": {
					Description: "Password for SMTP authentication",
					Optional:    true,
					Sensitive:   true,
					Type:        schema.TypeString,
				},
				"port": {
					Description: "SMTP server port",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"skip_verify": {
					Description: "Skip verifying server certificate. Defaults to false",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"starttls_policy": {
					Description: "Either OpportunisticStartTLS, MandatoryStartTLS or NoStartTLS. Default is OpportunisticStartTLS.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"username": {
					Description: "Username for SMTP authentication",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"from_address": {
					Description: "Address used for sending emails",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"from_name": {
					Description: "Name used in outgoing emails, defaults to Grafana",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"host": {
					Description: "Server hostname or IP",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"password": {
					Description: "Password for SMTP authentication",
					Optional:    true,
					Sensitive:   true,
					Type:        schema.TypeString,
				},
				"port": {
					Description: "SMTP server port",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"skip_verify": {
					Description: "Skip verifying server certificate. Defaults to false",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"starttls_policy": {
					Description: "Either OpportunisticStartTLS, MandatoryStartTLS or NoStartTLS. Default is OpportunisticStartTLS.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"username": {
					Description: "Username for SMTP authentication",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"static_ips": {
			Description: "Use static public IP addresses",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"user_auto_assign_org": {
			Description: "Auto-assign new users on signup to main organization. Defaults to false",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"user_auto_assign_org_role": {
			Description: "Set role for new signups. Defaults to Viewer",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"viewers_can_edit": {
			Description: "Users with view-only permission can edit but not save dashboards",
			Optional:    true,
			Type:        schema.TypeString,
		},
	}

	return &schema.Schema{
		Description:      "Grafana user configurable settings",
		DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(s),
		Elem:             &schema.Resource{Schema: s},
		MaxItems:         1,
		Optional:         true,
		Type:             schema.TypeList,
	}
}

// ServiceTypeInfluxdb is a generated function returning the schema of the influxdb ServiceType.
func ServiceTypeInfluxdb() *schema.Schema {
	s := map[string]*schema.Schema{
		"additional_backup_regions": {
			Description: "Additional Cloud Regions for Backup Replication",
			Elem:        &schema.Schema{Type: schema.TypeString},
			MaxItems:    1,
			Optional:    true,
			Type:        schema.TypeList,
		},
		"custom_domain": {
			Description: "Serve the web frontend using a custom CNAME pointing to the Aiven DNS name",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"influxdb": {
			Description: "influxdb.conf configuration values",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"log_queries_after": {
					Description: "The maximum duration in seconds before a query is logged as a slow query. Setting this to 0 (the default) will never log slow queries.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_connection_limit": {
					Description: "Maximum number of connections to InfluxDB. Setting this to 0 (default) means no limit. If using max_connection_limit, it is recommended to set the value to be large enough in order to not block clients unnecessarily.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_row_limit": {
					Description: "The maximum number of rows returned in a non-chunked query. Setting this to 0 (the default) allows an unlimited number to be returned.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_select_buckets": {
					Description: "The maximum number of `GROUP BY time()` buckets that can be processed in a query. Setting this to 0 (the default) allows an unlimited number to be processed.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_select_point": {
					Description: "The maximum number of points that can be processed in a SELECT statement. Setting this to 0 (the default) allows an unlimited number to be processed.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"query_timeout": {
					Description: "The maximum duration in seconds before a query is killed. Setting this to 0 (the default) will never kill slow queries.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"log_queries_after": {
					Description: "The maximum duration in seconds before a query is logged as a slow query. Setting this to 0 (the default) will never log slow queries.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_connection_limit": {
					Description: "Maximum number of connections to InfluxDB. Setting this to 0 (default) means no limit. If using max_connection_limit, it is recommended to set the value to be large enough in order to not block clients unnecessarily.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_row_limit": {
					Description: "The maximum number of rows returned in a non-chunked query. Setting this to 0 (the default) allows an unlimited number to be returned.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_select_buckets": {
					Description: "The maximum number of `GROUP BY time()` buckets that can be processed in a query. Setting this to 0 (the default) allows an unlimited number to be processed.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_select_point": {
					Description: "The maximum number of points that can be processed in a SELECT statement. Setting this to 0 (the default) allows an unlimited number to be processed.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"query_timeout": {
					Description: "The maximum duration in seconds before a query is killed. Setting this to 0 (the default) will never kill slow queries.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter": {
			Description:      "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			DiffSuppressFunc: schemautil.IPFilterArrayDiffSuppressFunc,
			Elem: &schema.Schema{
				DiffSuppressFunc: schemautil.IPFilterValueDiffSuppressFunc,
				Type:             schema.TypeString,
			},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter_object": {
			Description: "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"description": {
					Description: "Description for IP filter list entry",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"network": {
					Description: "CIDR address block",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"private_access": {
			Description: "Allow access to selected service ports from private networks",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{"influxdb": {
				Description: "Allow clients to connect to influxdb with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
				Optional:    true,
				Type:        schema.TypeString,
			}}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{"influxdb": {
				Description: "Allow clients to connect to influxdb with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
				Optional:    true,
				Type:        schema.TypeString,
			}}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"privatelink_access": {
			Description: "Allow access to selected service components through Privatelink",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{"influxdb": {
				Description: "Enable influxdb",
				Optional:    true,
				Type:        schema.TypeString,
			}}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{"influxdb": {
				Description: "Enable influxdb",
				Optional:    true,
				Type:        schema.TypeString,
			}}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"project_to_fork_from": {
			Description: "Name of another project to fork a service from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"public_access": {
			Description: "Allow access to selected service ports from the public Internet",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{"influxdb": {
				Description: "Allow clients to connect to influxdb from the public internet for service nodes that are in a project VPC or another type of private network",
				Optional:    true,
				Type:        schema.TypeString,
			}}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{"influxdb": {
				Description: "Allow clients to connect to influxdb from the public internet for service nodes that are in a project VPC or another type of private network",
				Optional:    true,
				Type:        schema.TypeString,
			}}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"recovery_basebackup_name": {
			Description: "Name of the basebackup to restore in forked service",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"service_to_fork_from": {
			Description: "Name of another service to fork from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"static_ips": {
			Description: "Use static public IP addresses",
			Optional:    true,
			Type:        schema.TypeString,
		},
	}

	return &schema.Schema{
		Description:      "Influxdb user configurable settings",
		DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(s),
		Elem:             &schema.Resource{Schema: s},
		MaxItems:         1,
		Optional:         true,
		Type:             schema.TypeList,
	}
}

// ServiceTypeKafka is a generated function returning the schema of the kafka ServiceType.
func ServiceTypeKafka() *schema.Schema {
	s := map[string]*schema.Schema{
		"additional_backup_regions": {
			Description: "Additional Cloud Regions for Backup Replication",
			Elem:        &schema.Schema{Type: schema.TypeString},
			MaxItems:    1,
			Optional:    true,
			Type:        schema.TypeList,
		},
		"custom_domain": {
			Description: "Serve the web frontend using a custom CNAME pointing to the Aiven DNS name",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"ip_filter": {
			Description:      "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			DiffSuppressFunc: schemautil.IPFilterArrayDiffSuppressFunc,
			Elem: &schema.Schema{
				DiffSuppressFunc: schemautil.IPFilterValueDiffSuppressFunc,
				Type:             schema.TypeString,
			},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter_object": {
			Description: "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"description": {
					Description: "Description for IP filter list entry",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"network": {
					Description: "CIDR address block",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"kafka": {
			Description: "Kafka broker configuration values",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"auto_create_topics_enable": {
					Description: "Enable auto creation of topics",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"compression_type": {
					Description: "Specify the final compression type for a given topic. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer' which means retain the original compression codec set by the producer.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"connections_max_idle_ms": {
					Description: "Idle connections timeout: the server socket processor threads close the connections that idle for longer than this.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"default_replication_factor": {
					Description: "Replication factor for autocreated topics",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"group_initial_rebalance_delay_ms": {
					Description: "The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"group_max_session_timeout_ms": {
					Description: "The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"group_min_session_timeout_ms": {
					Description: "The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_cleaner_delete_retention_ms": {
					Description: "How long are delete records retained?",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_cleaner_max_compaction_lag_ms": {
					Description: "The maximum amount of time message will remain uncompacted. Only applicable for logs that are being compacted",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_cleaner_min_cleanable_ratio": {
					Description: "Controls log compactor frequency. Larger value means more frequent compactions but also more space wasted for logs. Consider setting log.cleaner.max.compaction.lag.ms to enforce compactions sooner, instead of setting a very high value for this option.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_cleaner_min_compaction_lag_ms": {
					Description: "The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_cleanup_policy": {
					Description: "The default cleanup policy for segments beyond the retention window",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_flush_interval_messages": {
					Description: "The number of messages accumulated on a log partition before messages are flushed to disk",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_flush_interval_ms": {
					Description: "The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_index_interval_bytes": {
					Description: "The interval with which Kafka adds an entry to the offset index",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_index_size_max_bytes": {
					Description: "The maximum size in bytes of the offset index",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_message_downconversion_enable": {
					Description: "This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests. ",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_message_timestamp_difference_max_ms": {
					Description: "The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_message_timestamp_type": {
					Description: "Define whether the timestamp in the message is message create time or log append time.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_preallocate": {
					Description: "Should pre allocate file when create new segment?",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_retention_bytes": {
					Description: "The maximum size of the log before deleting messages",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_retention_hours": {
					Description: "The number of hours to keep a log file before deleting it",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_retention_ms": {
					Description: "The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_roll_jitter_ms": {
					Description: "The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_roll_ms": {
					Description: "The maximum time before a new log segment is rolled out (in milliseconds).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_segment_bytes": {
					Description: "The maximum size of a single log file",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_segment_delete_delay_ms": {
					Description: "The amount of time to wait before deleting a file from the filesystem",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_connections_per_ip": {
					Description: "The maximum number of connections allowed from each ip address (defaults to 2147483647).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_incremental_fetch_session_cache_slots": {
					Description: "The maximum number of incremental fetch sessions that the broker will maintain.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"message_max_bytes": {
					Description: "The maximum size of message that the server can receive.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"min_insync_replicas": {
					Description: "When a producer sets acks to 'all' (or '-1'), min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"num_partitions": {
					Description: "Number of partitions for autocreated topics",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"offsets_retention_minutes": {
					Description: "Log retention window in minutes for offsets topic",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"producer_purgatory_purge_interval_requests": {
					Description: "The purge interval (in number of requests) of the producer request purgatory(defaults to 1000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"replica_fetch_max_bytes": {
					Description: "The number of bytes of messages to attempt to fetch for each partition (defaults to 1048576). This is not an absolute maximum, if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"replica_fetch_response_max_bytes": {
					Description: "Maximum bytes expected for the entire fetch response (defaults to 10485760). Records are fetched in batches, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made. As such, this is not an absolute maximum.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"socket_request_max_bytes": {
					Description: "The maximum number of bytes in a socket request (defaults to 104857600).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"transaction_remove_expired_transaction_cleanup_interval_ms": {
					Description: "The interval at which to remove transactions that have expired due to transactional.id.expiration.ms passing (defaults to 3600000 (1 hour)).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"transaction_state_log_segment_bytes": {
					Description: "The transaction topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads (defaults to 104857600 (100 mebibytes)).",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"auto_create_topics_enable": {
					Description: "Enable auto creation of topics",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"compression_type": {
					Description: "Specify the final compression type for a given topic. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer' which means retain the original compression codec set by the producer.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"connections_max_idle_ms": {
					Description: "Idle connections timeout: the server socket processor threads close the connections that idle for longer than this.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"default_replication_factor": {
					Description: "Replication factor for autocreated topics",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"group_initial_rebalance_delay_ms": {
					Description: "The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"group_max_session_timeout_ms": {
					Description: "The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"group_min_session_timeout_ms": {
					Description: "The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_cleaner_delete_retention_ms": {
					Description: "How long are delete records retained?",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_cleaner_max_compaction_lag_ms": {
					Description: "The maximum amount of time message will remain uncompacted. Only applicable for logs that are being compacted",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_cleaner_min_cleanable_ratio": {
					Description: "Controls log compactor frequency. Larger value means more frequent compactions but also more space wasted for logs. Consider setting log.cleaner.max.compaction.lag.ms to enforce compactions sooner, instead of setting a very high value for this option.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_cleaner_min_compaction_lag_ms": {
					Description: "The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_cleanup_policy": {
					Description: "The default cleanup policy for segments beyond the retention window",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_flush_interval_messages": {
					Description: "The number of messages accumulated on a log partition before messages are flushed to disk",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_flush_interval_ms": {
					Description: "The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_index_interval_bytes": {
					Description: "The interval with which Kafka adds an entry to the offset index",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_index_size_max_bytes": {
					Description: "The maximum size in bytes of the offset index",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_message_downconversion_enable": {
					Description: "This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests. ",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_message_timestamp_difference_max_ms": {
					Description: "The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_message_timestamp_type": {
					Description: "Define whether the timestamp in the message is message create time or log append time.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_preallocate": {
					Description: "Should pre allocate file when create new segment?",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_retention_bytes": {
					Description: "The maximum size of the log before deleting messages",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_retention_hours": {
					Description: "The number of hours to keep a log file before deleting it",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_retention_ms": {
					Description: "The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_roll_jitter_ms": {
					Description: "The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_roll_ms": {
					Description: "The maximum time before a new log segment is rolled out (in milliseconds).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_segment_bytes": {
					Description: "The maximum size of a single log file",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_segment_delete_delay_ms": {
					Description: "The amount of time to wait before deleting a file from the filesystem",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_connections_per_ip": {
					Description: "The maximum number of connections allowed from each ip address (defaults to 2147483647).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_incremental_fetch_session_cache_slots": {
					Description: "The maximum number of incremental fetch sessions that the broker will maintain.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"message_max_bytes": {
					Description: "The maximum size of message that the server can receive.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"min_insync_replicas": {
					Description: "When a producer sets acks to 'all' (or '-1'), min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"num_partitions": {
					Description: "Number of partitions for autocreated topics",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"offsets_retention_minutes": {
					Description: "Log retention window in minutes for offsets topic",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"producer_purgatory_purge_interval_requests": {
					Description: "The purge interval (in number of requests) of the producer request purgatory(defaults to 1000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"replica_fetch_max_bytes": {
					Description: "The number of bytes of messages to attempt to fetch for each partition (defaults to 1048576). This is not an absolute maximum, if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"replica_fetch_response_max_bytes": {
					Description: "Maximum bytes expected for the entire fetch response (defaults to 10485760). Records are fetched in batches, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made. As such, this is not an absolute maximum.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"socket_request_max_bytes": {
					Description: "The maximum number of bytes in a socket request (defaults to 104857600).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"transaction_remove_expired_transaction_cleanup_interval_ms": {
					Description: "The interval at which to remove transactions that have expired due to transactional.id.expiration.ms passing (defaults to 3600000 (1 hour)).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"transaction_state_log_segment_bytes": {
					Description: "The transaction topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads (defaults to 104857600 (100 mebibytes)).",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"kafka_authentication_methods": {
			Description: "Kafka authentication methods",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"certificate": {
					Description: "Enable certificate/SSL authentication",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"sasl": {
					Description: "Enable SASL authentication",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"certificate": {
					Description: "Enable certificate/SSL authentication",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"sasl": {
					Description: "Enable SASL authentication",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"kafka_connect": {
			Description: "Enable Kafka Connect service",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"kafka_connect_config": {
			Description: "Kafka Connect configuration values",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"connector_client_config_override_policy": {
					Description: "Defines what client configurations can be overridden by the connector. Default is None",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_auto_offset_reset": {
					Description: "What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server. Default is earliest",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_fetch_max_bytes": {
					Description: "Records are fetched in batches by the consumer, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that the consumer can make progress. As such, this is not a absolute maximum.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_isolation_level": {
					Description: "Transaction read isolation level. read_uncommitted is the default, but read_committed can be used if consume-exactly-once behavior is desired.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_max_partition_fetch_bytes": {
					Description: "Records are fetched in batches by the consumer.If the first record batch in the first non-empty partition of the fetch is larger than this limit, the batch will still be returned to ensure that the consumer can make progress. ",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_max_poll_interval_ms": {
					Description: "The maximum delay in milliseconds between invocations of poll() when using consumer group management (defaults to 300000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_max_poll_records": {
					Description: "The maximum number of records returned in a single call to poll() (defaults to 500).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"offset_flush_interval_ms": {
					Description: "The interval at which to try committing offsets for tasks (defaults to 60000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"offset_flush_timeout_ms": {
					Description: "Maximum number of milliseconds to wait for records to flush and partition offset data to be committed to offset storage before cancelling the process and restoring the offset data to be committed in a future attempt (defaults to 5000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"producer_compression_type": {
					Description: "Specify the default compression type for producers. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'none' which is the default and equivalent to no compression.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"producer_max_request_size": {
					Description: "This setting will limit the number of record batches the producer will send in a single request to avoid sending huge requests.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"session_timeout_ms": {
					Description: "The timeout in milliseconds used to detect failures when using Kafka’s group management facilities (defaults to 10000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"connector_client_config_override_policy": {
					Description: "Defines what client configurations can be overridden by the connector. Default is None",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_auto_offset_reset": {
					Description: "What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server. Default is earliest",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_fetch_max_bytes": {
					Description: "Records are fetched in batches by the consumer, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that the consumer can make progress. As such, this is not a absolute maximum.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_isolation_level": {
					Description: "Transaction read isolation level. read_uncommitted is the default, but read_committed can be used if consume-exactly-once behavior is desired.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_max_partition_fetch_bytes": {
					Description: "Records are fetched in batches by the consumer.If the first record batch in the first non-empty partition of the fetch is larger than this limit, the batch will still be returned to ensure that the consumer can make progress. ",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_max_poll_interval_ms": {
					Description: "The maximum delay in milliseconds between invocations of poll() when using consumer group management (defaults to 300000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_max_poll_records": {
					Description: "The maximum number of records returned in a single call to poll() (defaults to 500).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"offset_flush_interval_ms": {
					Description: "The interval at which to try committing offsets for tasks (defaults to 60000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"offset_flush_timeout_ms": {
					Description: "Maximum number of milliseconds to wait for records to flush and partition offset data to be committed to offset storage before cancelling the process and restoring the offset data to be committed in a future attempt (defaults to 5000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"producer_compression_type": {
					Description: "Specify the default compression type for producers. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'none' which is the default and equivalent to no compression.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"producer_max_request_size": {
					Description: "This setting will limit the number of record batches the producer will send in a single request to avoid sending huge requests.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"session_timeout_ms": {
					Description: "The timeout in milliseconds used to detect failures when using Kafka’s group management facilities (defaults to 10000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"kafka_rest": {
			Description: "Enable Kafka-REST service",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"kafka_rest_config": {
			Description: "Kafka REST configuration",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"consumer_enable_auto_commit": {
					Description: "If true the consumer's offset will be periodically committed to Kafka in the background",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_request_max_bytes": {
					Description: "Maximum number of bytes in unencoded message keys and values by a single request",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_request_timeout_ms": {
					Description: "The maximum total time to wait for messages for a request if the maximum number of messages has not yet been reached",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"producer_acks": {
					Description: "The number of acknowledgments the producer requires the leader to have received before considering a request complete. If set to 'all' or '-1', the leader will wait for the full set of in-sync replicas to acknowledge the record.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"producer_linger_ms": {
					Description: "Wait for up to the given delay to allow batching records together",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"simpleconsumer_pool_size_max": {
					Description: "Maximum number of SimpleConsumers that can be instantiated per broker",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"consumer_enable_auto_commit": {
					Description: "If true the consumer's offset will be periodically committed to Kafka in the background",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_request_max_bytes": {
					Description: "Maximum number of bytes in unencoded message keys and values by a single request",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_request_timeout_ms": {
					Description: "The maximum total time to wait for messages for a request if the maximum number of messages has not yet been reached",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"producer_acks": {
					Description: "The number of acknowledgments the producer requires the leader to have received before considering a request complete. If set to 'all' or '-1', the leader will wait for the full set of in-sync replicas to acknowledge the record.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"producer_linger_ms": {
					Description: "Wait for up to the given delay to allow batching records together",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"simpleconsumer_pool_size_max": {
					Description: "Maximum number of SimpleConsumers that can be instantiated per broker",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"kafka_version": {
			Description: "Kafka major version",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"private_access": {
			Description: "Allow access to selected service ports from private networks",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{"prometheus": {
				Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
				Optional:    true,
				Type:        schema.TypeString,
			}}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{"prometheus": {
				Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
				Optional:    true,
				Type:        schema.TypeString,
			}}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"privatelink_access": {
			Description: "Allow access to selected service components through Privatelink",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"jolokia": {
					Description: "Enable jolokia",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kafka": {
					Description: "Enable kafka",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kafka_connect": {
					Description: "Enable kafka_connect",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kafka_rest": {
					Description: "Enable kafka_rest",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Enable prometheus",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"schema_registry": {
					Description: "Enable schema_registry",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"jolokia": {
					Description: "Enable jolokia",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kafka": {
					Description: "Enable kafka",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kafka_connect": {
					Description: "Enable kafka_connect",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kafka_rest": {
					Description: "Enable kafka_rest",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Enable prometheus",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"schema_registry": {
					Description: "Enable schema_registry",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"public_access": {
			Description: "Allow access to selected service ports from the public Internet",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"kafka": {
					Description: "Allow clients to connect to kafka from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kafka_connect": {
					Description: "Allow clients to connect to kafka_connect from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kafka_rest": {
					Description: "Allow clients to connect to kafka_rest from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"schema_registry": {
					Description: "Allow clients to connect to schema_registry from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"kafka": {
					Description: "Allow clients to connect to kafka from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kafka_connect": {
					Description: "Allow clients to connect to kafka_connect from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kafka_rest": {
					Description: "Allow clients to connect to kafka_rest from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"schema_registry": {
					Description: "Allow clients to connect to schema_registry from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"schema_registry": {
			Description: "Enable Schema-Registry service",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"schema_registry_config": {
			Description: "Schema Registry configuration",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"leader_eligibility": {
					Description: "If true, Karapace / Schema Registry on the service nodes can participate in leader election. It might be needed to disable this when the schemas topic is replicated to a secondary cluster and Karapace / Schema Registry there must not participate in leader election. Defaults to `true`.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"topic_name": {
					Description: "The durable single partition topic that acts as the durable log for the data. This topic must be compacted to avoid losing data due to retention policy. Please note that changing this configuration in an existing Schema Registry / Karapace setup leads to previous schemas being inaccessible, data encoded with them potentially unreadable and schema ID sequence put out of order. It's only possible to do the switch while Schema Registry / Karapace is disabled. Defaults to `_schemas`.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"leader_eligibility": {
					Description: "If true, Karapace / Schema Registry on the service nodes can participate in leader election. It might be needed to disable this when the schemas topic is replicated to a secondary cluster and Karapace / Schema Registry there must not participate in leader election. Defaults to `true`.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"topic_name": {
					Description: "The durable single partition topic that acts as the durable log for the data. This topic must be compacted to avoid losing data due to retention policy. Please note that changing this configuration in an existing Schema Registry / Karapace setup leads to previous schemas being inaccessible, data encoded with them potentially unreadable and schema ID sequence put out of order. It's only possible to do the switch while Schema Registry / Karapace is disabled. Defaults to `_schemas`.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"static_ips": {
			Description: "Use static public IP addresses",
			Optional:    true,
			Type:        schema.TypeString,
		},
	}

	return &schema.Schema{
		Description:      "Kafka user configurable settings",
		DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(s),
		Elem:             &schema.Resource{Schema: s},
		MaxItems:         1,
		Optional:         true,
		Type:             schema.TypeList,
	}
}

// ServiceTypeKafkaConnect is a generated function returning the schema of the kafka_connect ServiceType.
func ServiceTypeKafkaConnect() *schema.Schema {
	s := map[string]*schema.Schema{
		"additional_backup_regions": {
			Description: "Additional Cloud Regions for Backup Replication",
			Elem:        &schema.Schema{Type: schema.TypeString},
			MaxItems:    1,
			Optional:    true,
			Type:        schema.TypeList,
		},
		"ip_filter": {
			Description:      "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			DiffSuppressFunc: schemautil.IPFilterArrayDiffSuppressFunc,
			Elem: &schema.Schema{
				DiffSuppressFunc: schemautil.IPFilterValueDiffSuppressFunc,
				Type:             schema.TypeString,
			},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter_object": {
			Description: "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"description": {
					Description: "Description for IP filter list entry",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"network": {
					Description: "CIDR address block",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"kafka_connect": {
			Description: "Kafka Connect configuration values",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"connector_client_config_override_policy": {
					Description: "Defines what client configurations can be overridden by the connector. Default is None",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_auto_offset_reset": {
					Description: "What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server. Default is earliest",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_fetch_max_bytes": {
					Description: "Records are fetched in batches by the consumer, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that the consumer can make progress. As such, this is not a absolute maximum.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_isolation_level": {
					Description: "Transaction read isolation level. read_uncommitted is the default, but read_committed can be used if consume-exactly-once behavior is desired.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_max_partition_fetch_bytes": {
					Description: "Records are fetched in batches by the consumer.If the first record batch in the first non-empty partition of the fetch is larger than this limit, the batch will still be returned to ensure that the consumer can make progress. ",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_max_poll_interval_ms": {
					Description: "The maximum delay in milliseconds between invocations of poll() when using consumer group management (defaults to 300000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_max_poll_records": {
					Description: "The maximum number of records returned in a single call to poll() (defaults to 500).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"offset_flush_interval_ms": {
					Description: "The interval at which to try committing offsets for tasks (defaults to 60000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"offset_flush_timeout_ms": {
					Description: "Maximum number of milliseconds to wait for records to flush and partition offset data to be committed to offset storage before cancelling the process and restoring the offset data to be committed in a future attempt (defaults to 5000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"producer_compression_type": {
					Description: "Specify the default compression type for producers. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'none' which is the default and equivalent to no compression.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"producer_max_request_size": {
					Description: "This setting will limit the number of record batches the producer will send in a single request to avoid sending huge requests.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"session_timeout_ms": {
					Description: "The timeout in milliseconds used to detect failures when using Kafka’s group management facilities (defaults to 10000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"connector_client_config_override_policy": {
					Description: "Defines what client configurations can be overridden by the connector. Default is None",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_auto_offset_reset": {
					Description: "What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server. Default is earliest",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_fetch_max_bytes": {
					Description: "Records are fetched in batches by the consumer, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that the consumer can make progress. As such, this is not a absolute maximum.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_isolation_level": {
					Description: "Transaction read isolation level. read_uncommitted is the default, but read_committed can be used if consume-exactly-once behavior is desired.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_max_partition_fetch_bytes": {
					Description: "Records are fetched in batches by the consumer.If the first record batch in the first non-empty partition of the fetch is larger than this limit, the batch will still be returned to ensure that the consumer can make progress. ",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_max_poll_interval_ms": {
					Description: "The maximum delay in milliseconds between invocations of poll() when using consumer group management (defaults to 300000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"consumer_max_poll_records": {
					Description: "The maximum number of records returned in a single call to poll() (defaults to 500).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"offset_flush_interval_ms": {
					Description: "The interval at which to try committing offsets for tasks (defaults to 60000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"offset_flush_timeout_ms": {
					Description: "Maximum number of milliseconds to wait for records to flush and partition offset data to be committed to offset storage before cancelling the process and restoring the offset data to be committed in a future attempt (defaults to 5000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"producer_compression_type": {
					Description: "Specify the default compression type for producers. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'none' which is the default and equivalent to no compression.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"producer_max_request_size": {
					Description: "This setting will limit the number of record batches the producer will send in a single request to avoid sending huge requests.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"session_timeout_ms": {
					Description: "The timeout in milliseconds used to detect failures when using Kafka’s group management facilities (defaults to 10000).",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"private_access": {
			Description: "Allow access to selected service ports from private networks",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"kafka_connect": {
					Description: "Allow clients to connect to kafka_connect with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"kafka_connect": {
					Description: "Allow clients to connect to kafka_connect with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"privatelink_access": {
			Description: "Allow access to selected service components through Privatelink",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"jolokia": {
					Description: "Enable jolokia",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kafka_connect": {
					Description: "Enable kafka_connect",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Enable prometheus",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"jolokia": {
					Description: "Enable jolokia",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"kafka_connect": {
					Description: "Enable kafka_connect",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Enable prometheus",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"public_access": {
			Description: "Allow access to selected service ports from the public Internet",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"kafka_connect": {
					Description: "Allow clients to connect to kafka_connect from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"kafka_connect": {
					Description: "Allow clients to connect to kafka_connect from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"static_ips": {
			Description: "Use static public IP addresses",
			Optional:    true,
			Type:        schema.TypeString,
		},
	}

	return &schema.Schema{
		Description:      "KafkaConnect user configurable settings",
		DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(s),
		Elem:             &schema.Resource{Schema: s},
		MaxItems:         1,
		Optional:         true,
		Type:             schema.TypeList,
	}
}

// ServiceTypeKafkaMirrormaker is a generated function returning the schema of the kafka_mirrormaker ServiceType.
func ServiceTypeKafkaMirrormaker() *schema.Schema {
	s := map[string]*schema.Schema{
		"additional_backup_regions": {
			Description: "Additional Cloud Regions for Backup Replication",
			Elem:        &schema.Schema{Type: schema.TypeString},
			MaxItems:    1,
			Optional:    true,
			Type:        schema.TypeList,
		},
		"ip_filter": {
			Description:      "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			DiffSuppressFunc: schemautil.IPFilterArrayDiffSuppressFunc,
			Elem: &schema.Schema{
				DiffSuppressFunc: schemautil.IPFilterValueDiffSuppressFunc,
				Type:             schema.TypeString,
			},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter_object": {
			Description: "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"description": {
					Description: "Description for IP filter list entry",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"network": {
					Description: "CIDR address block",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"kafka_mirrormaker": {
			Description: "Kafka MirrorMaker configuration values",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"emit_checkpoints_enabled": {
					Description: "Whether to emit consumer group offset checkpoints to target cluster periodically (default: true)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"emit_checkpoints_interval_seconds": {
					Description: "Frequency at which consumer group offset checkpoints are emitted (default: 60, every minute)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"refresh_groups_enabled": {
					Description: "Whether to periodically check for new consumer groups. Defaults to 'true'.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"refresh_groups_interval_seconds": {
					Description: "Frequency of consumer group refresh in seconds. Defaults to 600 seconds (10 minutes).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"refresh_topics_enabled": {
					Description: "Whether to periodically check for new topics and partitions. Defaults to 'true'.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"refresh_topics_interval_seconds": {
					Description: "Frequency of topic and partitions refresh in seconds. Defaults to 600 seconds (10 minutes).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"sync_group_offsets_enabled": {
					Description: "Whether to periodically write the translated offsets of replicated consumer groups (in the source cluster) to __consumer_offsets topic in target cluster, as long as no active consumers in that group are connected to the target cluster",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"sync_group_offsets_interval_seconds": {
					Description: "Frequency at which consumer group offsets are synced (default: 60, every minute)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"sync_topic_configs_enabled": {
					Description: "Whether to periodically configure remote topics to match their corresponding upstream topics.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"tasks_max_per_cpu": {
					Description: "'tasks.max' is set to this multiplied by the number of CPUs in the service.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"emit_checkpoints_enabled": {
					Description: "Whether to emit consumer group offset checkpoints to target cluster periodically (default: true)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"emit_checkpoints_interval_seconds": {
					Description: "Frequency at which consumer group offset checkpoints are emitted (default: 60, every minute)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"refresh_groups_enabled": {
					Description: "Whether to periodically check for new consumer groups. Defaults to 'true'.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"refresh_groups_interval_seconds": {
					Description: "Frequency of consumer group refresh in seconds. Defaults to 600 seconds (10 minutes).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"refresh_topics_enabled": {
					Description: "Whether to periodically check for new topics and partitions. Defaults to 'true'.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"refresh_topics_interval_seconds": {
					Description: "Frequency of topic and partitions refresh in seconds. Defaults to 600 seconds (10 minutes).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"sync_group_offsets_enabled": {
					Description: "Whether to periodically write the translated offsets of replicated consumer groups (in the source cluster) to __consumer_offsets topic in target cluster, as long as no active consumers in that group are connected to the target cluster",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"sync_group_offsets_interval_seconds": {
					Description: "Frequency at which consumer group offsets are synced (default: 60, every minute)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"sync_topic_configs_enabled": {
					Description: "Whether to periodically configure remote topics to match their corresponding upstream topics.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"tasks_max_per_cpu": {
					Description: "'tasks.max' is set to this multiplied by the number of CPUs in the service.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"static_ips": {
			Description: "Use static public IP addresses",
			Optional:    true,
			Type:        schema.TypeString,
		},
	}

	return &schema.Schema{
		Description:      "KafkaMirrormaker user configurable settings",
		DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(s),
		Elem:             &schema.Resource{Schema: s},
		MaxItems:         1,
		Optional:         true,
		Type:             schema.TypeList,
	}
}

// ServiceTypeM3aggregator is a generated function returning the schema of the m3aggregator ServiceType.
func ServiceTypeM3aggregator() *schema.Schema {
	s := map[string]*schema.Schema{
		"custom_domain": {
			Description: "Serve the web frontend using a custom CNAME pointing to the Aiven DNS name",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"ip_filter": {
			Description:      "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			DiffSuppressFunc: schemautil.IPFilterArrayDiffSuppressFunc,
			Elem: &schema.Schema{
				DiffSuppressFunc: schemautil.IPFilterValueDiffSuppressFunc,
				Type:             schema.TypeString,
			},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter_object": {
			Description: "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"description": {
					Description: "Description for IP filter list entry",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"network": {
					Description: "CIDR address block",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"m3_version": {
			Description: "M3 major version (deprecated, use m3aggregator_version)",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"m3aggregator_version": {
			Description: "M3 major version (the minimum compatible version)",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"static_ips": {
			Description: "Use static public IP addresses",
			Optional:    true,
			Type:        schema.TypeString,
		},
	}

	return &schema.Schema{
		Description:      "M3aggregator user configurable settings",
		DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(s),
		Elem:             &schema.Resource{Schema: s},
		MaxItems:         1,
		Optional:         true,
		Type:             schema.TypeList,
	}
}

// ServiceTypeM3db is a generated function returning the schema of the m3db ServiceType.
func ServiceTypeM3db() *schema.Schema {
	s := map[string]*schema.Schema{
		"additional_backup_regions": {
			Description: "Additional Cloud Regions for Backup Replication",
			Elem:        &schema.Schema{Type: schema.TypeString},
			MaxItems:    1,
			Optional:    true,
			Type:        schema.TypeList,
		},
		"custom_domain": {
			Description: "Serve the web frontend using a custom CNAME pointing to the Aiven DNS name",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"ip_filter": {
			Description:      "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			DiffSuppressFunc: schemautil.IPFilterArrayDiffSuppressFunc,
			Elem: &schema.Schema{
				DiffSuppressFunc: schemautil.IPFilterValueDiffSuppressFunc,
				Type:             schema.TypeString,
			},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter_object": {
			Description: "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"description": {
					Description: "Description for IP filter list entry",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"network": {
					Description: "CIDR address block",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"limits": {
			Description: "M3 limits",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"max_recently_queried_series_blocks": {
					Description: "The maximum number of blocks that can be read in a given lookback period.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_recently_queried_series_disk_bytes_read": {
					Description: "The maximum number of disk bytes that can be read in a given lookback period.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_recently_queried_series_lookback": {
					Description: "The lookback period for 'max_recently_queried_series_blocks' and 'max_recently_queried_series_disk_bytes_read'.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"query_docs": {
					Description: "The maximum number of docs fetched in single query.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"query_require_exhaustive": {
					Description: "When query limits are exceeded, whether to return error or return partial results.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"query_series": {
					Description: "The maximum number of series fetched in single query.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"max_recently_queried_series_blocks": {
					Description: "The maximum number of blocks that can be read in a given lookback period.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_recently_queried_series_disk_bytes_read": {
					Description: "The maximum number of disk bytes that can be read in a given lookback period.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_recently_queried_series_lookback": {
					Description: "The lookback period for 'max_recently_queried_series_blocks' and 'max_recently_queried_series_disk_bytes_read'.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"query_docs": {
					Description: "The maximum number of docs fetched in single query.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"query_require_exhaustive": {
					Description: "When query limits are exceeded, whether to return error or return partial results.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"query_series": {
					Description: "The maximum number of series fetched in single query.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"m3_version": {
			Description: "M3 major version (deprecated, use m3db_version)",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"m3coordinator_enable_graphite_carbon_ingest": {
			Description: "Enables access to Graphite Carbon plaintext metrics ingestion. It can be enabled only for services inside VPCs. The metrics are written to aggregated namespaces only.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"m3db_version": {
			Description: "M3 major version (the minimum compatible version)",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"namespaces": {
			Description: "List of M3 namespaces",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"name": {
					Description: "The name of the namespace",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"options": {
					Description: "Namespace options",
					DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
						"retention_options": {
							Description: "Retention options",
							DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
								"block_data_expiry_duration": {
									Description: "Controls how long we wait before expiring stale data",
									Optional:    true,
									Type:        schema.TypeString,
								},
								"blocksize_duration": {
									Description: "Controls how long to keep a block in memory before flushing to a fileset on disk",
									Optional:    true,
									Type:        schema.TypeString,
								},
								"buffer_future_duration": {
									Description: "Controls how far into the future writes to the namespace will be accepted",
									Optional:    true,
									Type:        schema.TypeString,
								},
								"buffer_past_duration": {
									Description: "Controls how far into the past writes to the namespace will be accepted",
									Optional:    true,
									Type:        schema.TypeString,
								},
								"retention_period_duration": {
									Description: "Controls the duration of time that M3DB will retain data for the namespace",
									Optional:    true,
									Type:        schema.TypeString,
								},
							}),
							Elem: &schema.Resource{Schema: map[string]*schema.Schema{
								"block_data_expiry_duration": {
									Description: "Controls how long we wait before expiring stale data",
									Optional:    true,
									Type:        schema.TypeString,
								},
								"blocksize_duration": {
									Description: "Controls how long to keep a block in memory before flushing to a fileset on disk",
									Optional:    true,
									Type:        schema.TypeString,
								},
								"buffer_future_duration": {
									Description: "Controls how far into the future writes to the namespace will be accepted",
									Optional:    true,
									Type:        schema.TypeString,
								},
								"buffer_past_duration": {
									Description: "Controls how far into the past writes to the namespace will be accepted",
									Optional:    true,
									Type:        schema.TypeString,
								},
								"retention_period_duration": {
									Description: "Controls the duration of time that M3DB will retain data for the namespace",
									Optional:    true,
									Type:        schema.TypeString,
								},
							}},
							MaxItems: 1,
							Optional: true,
							Type:     schema.TypeList,
						},
						"snapshot_enabled": {
							Description: "Controls whether M3DB will create snapshot files for this namespace",
							Optional:    true,
							Type:        schema.TypeString,
						},
						"writes_to_commitlog": {
							Description: "Controls whether M3DB will include writes to this namespace in the commitlog",
							Optional:    true,
							Type:        schema.TypeString,
						},
					}),
					Elem: &schema.Resource{Schema: map[string]*schema.Schema{
						"retention_options": {
							Description: "Retention options",
							DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
								"block_data_expiry_duration": {
									Description: "Controls how long we wait before expiring stale data",
									Optional:    true,
									Type:        schema.TypeString,
								},
								"blocksize_duration": {
									Description: "Controls how long to keep a block in memory before flushing to a fileset on disk",
									Optional:    true,
									Type:        schema.TypeString,
								},
								"buffer_future_duration": {
									Description: "Controls how far into the future writes to the namespace will be accepted",
									Optional:    true,
									Type:        schema.TypeString,
								},
								"buffer_past_duration": {
									Description: "Controls how far into the past writes to the namespace will be accepted",
									Optional:    true,
									Type:        schema.TypeString,
								},
								"retention_period_duration": {
									Description: "Controls the duration of time that M3DB will retain data for the namespace",
									Optional:    true,
									Type:        schema.TypeString,
								},
							}),
							Elem: &schema.Resource{Schema: map[string]*schema.Schema{
								"block_data_expiry_duration": {
									Description: "Controls how long we wait before expiring stale data",
									Optional:    true,
									Type:        schema.TypeString,
								},
								"blocksize_duration": {
									Description: "Controls how long to keep a block in memory before flushing to a fileset on disk",
									Optional:    true,
									Type:        schema.TypeString,
								},
								"buffer_future_duration": {
									Description: "Controls how far into the future writes to the namespace will be accepted",
									Optional:    true,
									Type:        schema.TypeString,
								},
								"buffer_past_duration": {
									Description: "Controls how far into the past writes to the namespace will be accepted",
									Optional:    true,
									Type:        schema.TypeString,
								},
								"retention_period_duration": {
									Description: "Controls the duration of time that M3DB will retain data for the namespace",
									Optional:    true,
									Type:        schema.TypeString,
								},
							}},
							MaxItems: 1,
							Optional: true,
							Type:     schema.TypeList,
						},
						"snapshot_enabled": {
							Description: "Controls whether M3DB will create snapshot files for this namespace",
							Optional:    true,
							Type:        schema.TypeString,
						},
						"writes_to_commitlog": {
							Description: "Controls whether M3DB will include writes to this namespace in the commitlog",
							Optional:    true,
							Type:        schema.TypeString,
						},
					}},
					MaxItems: 1,
					Optional: true,
					Type:     schema.TypeList,
				},
				"resolution": {
					Description: "The resolution for an aggregated namespace",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"type": {
					Description: "The type of aggregation (aggregated/unaggregated)",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 2147483647,
			Optional: true,
			Type:     schema.TypeList,
		},
		"private_access": {
			Description: "Allow access to selected service ports from private networks",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{"m3coordinator": {
				Description: "Allow clients to connect to m3coordinator with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
				Optional:    true,
				Type:        schema.TypeString,
			}}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{"m3coordinator": {
				Description: "Allow clients to connect to m3coordinator with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
				Optional:    true,
				Type:        schema.TypeString,
			}}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"project_to_fork_from": {
			Description: "Name of another project to fork a service from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"public_access": {
			Description: "Allow access to selected service ports from the public Internet",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{"m3coordinator": {
				Description: "Allow clients to connect to m3coordinator from the public internet for service nodes that are in a project VPC or another type of private network",
				Optional:    true,
				Type:        schema.TypeString,
			}}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{"m3coordinator": {
				Description: "Allow clients to connect to m3coordinator from the public internet for service nodes that are in a project VPC or another type of private network",
				Optional:    true,
				Type:        schema.TypeString,
			}}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"rules": {
			Description: "M3 rules",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{"mapping": {
				Description: "List of M3 mapping rules",
				Elem: &schema.Resource{Schema: map[string]*schema.Schema{
					"aggregations": {
						Description: "List of aggregations to be applied",
						Elem:        &schema.Schema{Type: schema.TypeString},
						MaxItems:    10,
						Optional:    true,
						Type:        schema.TypeList,
					},
					"drop": {
						Description: "Only store the derived metric (as specified in the roll-up rules), if any",
						Optional:    true,
						Type:        schema.TypeString,
					},
					"filter": {
						Description: "Matching metric names with wildcards (using __name__:wildcard) or matching tags and their (optionally wildcarded) values. For value, ! can be used at start of value for negation, and multiple filters can be supplied using space as separator.",
						Optional:    true,
						Type:        schema.TypeString,
					},
					"name": {
						Description: "The (optional) name of the rule",
						Optional:    true,
						Type:        schema.TypeString,
					},
					"namespaces": {
						Description: "This rule will be used to store the metrics in the given namespace(s). If a namespace is target of rules, the global default aggregation will be automatically disabled. Note that specifying filters that match no namespaces whatsoever will be returned as an error. Filter the namespace by glob (=wildcards)",
						Elem:        &schema.Schema{Type: schema.TypeString},
						MaxItems:    10,
						Optional:    true,
						Type:        schema.TypeList,
					},
					"namespaces_object": {
						Description: "This rule will be used to store the metrics in the given namespace(s). If a namespace is target of rules, the global default aggregation will be automatically disabled. Note that specifying filters that match no namespaces whatsoever will be returned as an error. Filter the namespace by exact match of retention period and resolution",
						Elem: &schema.Resource{Schema: map[string]*schema.Schema{
							"resolution": {
								Description: "The resolution for the matching namespace",
								Optional:    true,
								Type:        schema.TypeString,
							},
							"retention": {
								Description: "The retention period of the matching namespace",
								Optional:    true,
								Type:        schema.TypeString,
							},
						}},
						MaxItems: 10,
						Optional: true,
						Type:     schema.TypeList,
					},
					"tags": {
						Description: "List of tags to be appended to matching metrics",
						Elem: &schema.Resource{Schema: map[string]*schema.Schema{
							"name": {
								Description: "Name of the tag",
								Optional:    true,
								Type:        schema.TypeString,
							},
							"value": {
								Description: "Value of the tag",
								Optional:    true,
								Type:        schema.TypeString,
							},
						}},
						MaxItems: 10,
						Optional: true,
						Type:     schema.TypeList,
					},
				}},
				MaxItems: 10,
				Optional: true,
				Type:     schema.TypeList,
			}}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{"mapping": {
				Description: "List of M3 mapping rules",
				Elem: &schema.Resource{Schema: map[string]*schema.Schema{
					"aggregations": {
						Description: "List of aggregations to be applied",
						Elem:        &schema.Schema{Type: schema.TypeString},
						MaxItems:    10,
						Optional:    true,
						Type:        schema.TypeList,
					},
					"drop": {
						Description: "Only store the derived metric (as specified in the roll-up rules), if any",
						Optional:    true,
						Type:        schema.TypeString,
					},
					"filter": {
						Description: "Matching metric names with wildcards (using __name__:wildcard) or matching tags and their (optionally wildcarded) values. For value, ! can be used at start of value for negation, and multiple filters can be supplied using space as separator.",
						Optional:    true,
						Type:        schema.TypeString,
					},
					"name": {
						Description: "The (optional) name of the rule",
						Optional:    true,
						Type:        schema.TypeString,
					},
					"namespaces": {
						Description: "This rule will be used to store the metrics in the given namespace(s). If a namespace is target of rules, the global default aggregation will be automatically disabled. Note that specifying filters that match no namespaces whatsoever will be returned as an error. Filter the namespace by glob (=wildcards)",
						Elem:        &schema.Schema{Type: schema.TypeString},
						MaxItems:    10,
						Optional:    true,
						Type:        schema.TypeList,
					},
					"namespaces_object": {
						Description: "This rule will be used to store the metrics in the given namespace(s). If a namespace is target of rules, the global default aggregation will be automatically disabled. Note that specifying filters that match no namespaces whatsoever will be returned as an error. Filter the namespace by exact match of retention period and resolution",
						Elem: &schema.Resource{Schema: map[string]*schema.Schema{
							"resolution": {
								Description: "The resolution for the matching namespace",
								Optional:    true,
								Type:        schema.TypeString,
							},
							"retention": {
								Description: "The retention period of the matching namespace",
								Optional:    true,
								Type:        schema.TypeString,
							},
						}},
						MaxItems: 10,
						Optional: true,
						Type:     schema.TypeList,
					},
					"tags": {
						Description: "List of tags to be appended to matching metrics",
						Elem: &schema.Resource{Schema: map[string]*schema.Schema{
							"name": {
								Description: "Name of the tag",
								Optional:    true,
								Type:        schema.TypeString,
							},
							"value": {
								Description: "Value of the tag",
								Optional:    true,
								Type:        schema.TypeString,
							},
						}},
						MaxItems: 10,
						Optional: true,
						Type:     schema.TypeList,
					},
				}},
				MaxItems: 10,
				Optional: true,
				Type:     schema.TypeList,
			}}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"service_to_fork_from": {
			Description: "Name of another service to fork from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"static_ips": {
			Description: "Use static public IP addresses",
			Optional:    true,
			Type:        schema.TypeString,
		},
	}

	return &schema.Schema{
		Description:      "M3db user configurable settings",
		DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(s),
		Elem:             &schema.Resource{Schema: s},
		MaxItems:         1,
		Optional:         true,
		Type:             schema.TypeList,
	}
}

// ServiceTypeMysql is a generated function returning the schema of the mysql ServiceType.
func ServiceTypeMysql() *schema.Schema {
	s := map[string]*schema.Schema{
		"additional_backup_regions": {
			Description: "Additional Cloud Regions for Backup Replication",
			Elem:        &schema.Schema{Type: schema.TypeString},
			MaxItems:    1,
			Optional:    true,
			Type:        schema.TypeList,
		},
		"admin_password": {
			Description: "Custom password for admin user. Defaults to random string. This must be set only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Sensitive:   true,
			Type:        schema.TypeString,
		},
		"admin_username": {
			Description: "Custom username for admin user. This must be set only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"backup_hour": {
			Description: "The hour of day (in UTC) when backup for the service is started. New backup is only started if previous backup has already completed.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"backup_minute": {
			Description: "The minute of an hour when backup for the service is started. New backup is only started if previous backup has already completed.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"binlog_retention_period": {
			Description: "The minimum amount of time in seconds to keep binlog entries before deletion. This may be extended for services that require binlog entries for longer than the default for example if using the MySQL Debezium Kafka connector.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"ip_filter": {
			Description:      "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			DiffSuppressFunc: schemautil.IPFilterArrayDiffSuppressFunc,
			Elem: &schema.Schema{
				DiffSuppressFunc: schemautil.IPFilterValueDiffSuppressFunc,
				Type:             schema.TypeString,
			},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter_object": {
			Description: "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"description": {
					Description: "Description for IP filter list entry",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"network": {
					Description: "CIDR address block",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"migration": {
			Description: "Migrate data from existing server",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"dbname": {
					Description: "Database name for bootstrapping the initial connection",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"host": {
					Description: "Hostname or IP address of the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"ignore_dbs": {
					Description: "Comma-separated list of databases, which should be ignored during migration (supported by MySQL only at the moment)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"method": {
					Description: "The migration method to be used (currently supported only by Redis and MySQL service types)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"password": {
					Description: "Password for authentication with the server where to migrate data from",
					Optional:    true,
					Sensitive:   true,
					Type:        schema.TypeString,
				},
				"port": {
					Description: "Port number of the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"ssl": {
					Description: "The server where to migrate data from is secured with SSL",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"username": {
					Description: "User name for authentication with the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"dbname": {
					Description: "Database name for bootstrapping the initial connection",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"host": {
					Description: "Hostname or IP address of the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"ignore_dbs": {
					Description: "Comma-separated list of databases, which should be ignored during migration (supported by MySQL only at the moment)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"method": {
					Description: "The migration method to be used (currently supported only by Redis and MySQL service types)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"password": {
					Description: "Password for authentication with the server where to migrate data from",
					Optional:    true,
					Sensitive:   true,
					Type:        schema.TypeString,
				},
				"port": {
					Description: "Port number of the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"ssl": {
					Description: "The server where to migrate data from is secured with SSL",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"username": {
					Description: "User name for authentication with the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"mysql": {
			Description: "mysql.conf configuration values",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"connect_timeout": {
					Description: "The number of seconds that the mysqld server waits for a connect packet before responding with Bad handshake",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"default_time_zone": {
					Description: "Default server time zone as an offset from UTC (from -12:00 to +12:00), a time zone name, or 'SYSTEM' to use the MySQL server default.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"group_concat_max_len": {
					Description: "The maximum permitted result length in bytes for the GROUP_CONCAT() function.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"information_schema_stats_expiry": {
					Description: "The time, in seconds, before cached statistics expire",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_change_buffer_max_size": {
					Description: "Maximum size for the InnoDB change buffer, as a percentage of the total size of the buffer pool. Default is 25",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_flush_neighbors": {
					Description: "Specifies whether flushing a page from the InnoDB buffer pool also flushes other dirty pages in the same extent (default is 1): 0 - dirty pages in the same extent are not flushed,  1 - flush contiguous dirty pages in the same extent,  2 - flush dirty pages in the same extent",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_ft_min_token_size": {
					Description: "Minimum length of words that are stored in an InnoDB FULLTEXT index. Changing this parameter will lead to a restart of the MySQL service.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_ft_server_stopword_table": {
					Description: "This option is used to specify your own InnoDB FULLTEXT index stopword list for all InnoDB tables.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_lock_wait_timeout": {
					Description: "The length of time in seconds an InnoDB transaction waits for a row lock before giving up.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_log_buffer_size": {
					Description: "The size in bytes of the buffer that InnoDB uses to write to the log files on disk.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_online_alter_log_max_size": {
					Description: "The upper limit in bytes on the size of the temporary log files used during online DDL operations for InnoDB tables.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_print_all_deadlocks": {
					Description: "When enabled, information about all deadlocks in InnoDB user transactions is recorded in the error log. Disabled by default.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_read_io_threads": {
					Description: "The number of I/O threads for read operations in InnoDB. Default is 4. Changing this parameter will lead to a restart of the MySQL service.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_rollback_on_timeout": {
					Description: "When enabled a transaction timeout causes InnoDB to abort and roll back the entire transaction. Changing this parameter will lead to a restart of the MySQL service.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_thread_concurrency": {
					Description: "Defines the maximum number of threads permitted inside of InnoDB. Default is 0 (infinite concurrency - no limit)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_write_io_threads": {
					Description: "The number of I/O threads for write operations in InnoDB. Default is 4. Changing this parameter will lead to a restart of the MySQL service.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"interactive_timeout": {
					Description: "The number of seconds the server waits for activity on an interactive connection before closing it.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"internal_tmp_mem_storage_engine": {
					Description: "The storage engine for in-memory internal temporary tables.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"long_query_time": {
					Description: "The slow_query_logs work as SQL statements that take more than long_query_time seconds to execute. Default is 10s",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_allowed_packet": {
					Description: "Size of the largest message in bytes that can be received by the server. Default is 67108864 (64M)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_heap_table_size": {
					Description: "Limits the size of internal in-memory tables. Also set tmp_table_size. Default is 16777216 (16M)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"net_buffer_length": {
					Description: "Start sizes of connection buffer and result buffer. Default is 16384 (16K). Changing this parameter will lead to a restart of the MySQL service.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"net_read_timeout": {
					Description: "The number of seconds to wait for more data from a connection before aborting the read.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"net_write_timeout": {
					Description: "The number of seconds to wait for a block to be written to a connection before aborting the write.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"slow_query_log": {
					Description: "Slow query log enables capturing of slow queries. Setting slow_query_log to false also truncates the mysql.slow_log table. Default is off",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"sort_buffer_size": {
					Description: "Sort buffer size in bytes for ORDER BY optimization. Default is 262144 (256K)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"sql_mode": {
					Description: "Global SQL mode. Set to empty to use MySQL server defaults. When creating a new service and not setting this field Aiven default SQL mode (strict, SQL standard compliant) will be assigned.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"sql_require_primary_key": {
					Description: "Require primary key to be defined for new tables or old tables modified with ALTER TABLE and fail if missing. It is recommended to always have primary keys because various functionality may break if any large table is missing them.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"tmp_table_size": {
					Description: "Limits the size of internal in-memory tables. Also set max_heap_table_size. Default is 16777216 (16M)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"wait_timeout": {
					Description: "The number of seconds the server waits for activity on a noninteractive connection before closing it.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"connect_timeout": {
					Description: "The number of seconds that the mysqld server waits for a connect packet before responding with Bad handshake",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"default_time_zone": {
					Description: "Default server time zone as an offset from UTC (from -12:00 to +12:00), a time zone name, or 'SYSTEM' to use the MySQL server default.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"group_concat_max_len": {
					Description: "The maximum permitted result length in bytes for the GROUP_CONCAT() function.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"information_schema_stats_expiry": {
					Description: "The time, in seconds, before cached statistics expire",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_change_buffer_max_size": {
					Description: "Maximum size for the InnoDB change buffer, as a percentage of the total size of the buffer pool. Default is 25",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_flush_neighbors": {
					Description: "Specifies whether flushing a page from the InnoDB buffer pool also flushes other dirty pages in the same extent (default is 1): 0 - dirty pages in the same extent are not flushed,  1 - flush contiguous dirty pages in the same extent,  2 - flush dirty pages in the same extent",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_ft_min_token_size": {
					Description: "Minimum length of words that are stored in an InnoDB FULLTEXT index. Changing this parameter will lead to a restart of the MySQL service.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_ft_server_stopword_table": {
					Description: "This option is used to specify your own InnoDB FULLTEXT index stopword list for all InnoDB tables.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_lock_wait_timeout": {
					Description: "The length of time in seconds an InnoDB transaction waits for a row lock before giving up.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_log_buffer_size": {
					Description: "The size in bytes of the buffer that InnoDB uses to write to the log files on disk.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_online_alter_log_max_size": {
					Description: "The upper limit in bytes on the size of the temporary log files used during online DDL operations for InnoDB tables.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_print_all_deadlocks": {
					Description: "When enabled, information about all deadlocks in InnoDB user transactions is recorded in the error log. Disabled by default.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_read_io_threads": {
					Description: "The number of I/O threads for read operations in InnoDB. Default is 4. Changing this parameter will lead to a restart of the MySQL service.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_rollback_on_timeout": {
					Description: "When enabled a transaction timeout causes InnoDB to abort and roll back the entire transaction. Changing this parameter will lead to a restart of the MySQL service.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_thread_concurrency": {
					Description: "Defines the maximum number of threads permitted inside of InnoDB. Default is 0 (infinite concurrency - no limit)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"innodb_write_io_threads": {
					Description: "The number of I/O threads for write operations in InnoDB. Default is 4. Changing this parameter will lead to a restart of the MySQL service.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"interactive_timeout": {
					Description: "The number of seconds the server waits for activity on an interactive connection before closing it.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"internal_tmp_mem_storage_engine": {
					Description: "The storage engine for in-memory internal temporary tables.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"long_query_time": {
					Description: "The slow_query_logs work as SQL statements that take more than long_query_time seconds to execute. Default is 10s",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_allowed_packet": {
					Description: "Size of the largest message in bytes that can be received by the server. Default is 67108864 (64M)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_heap_table_size": {
					Description: "Limits the size of internal in-memory tables. Also set tmp_table_size. Default is 16777216 (16M)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"net_buffer_length": {
					Description: "Start sizes of connection buffer and result buffer. Default is 16384 (16K). Changing this parameter will lead to a restart of the MySQL service.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"net_read_timeout": {
					Description: "The number of seconds to wait for more data from a connection before aborting the read.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"net_write_timeout": {
					Description: "The number of seconds to wait for a block to be written to a connection before aborting the write.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"slow_query_log": {
					Description: "Slow query log enables capturing of slow queries. Setting slow_query_log to false also truncates the mysql.slow_log table. Default is off",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"sort_buffer_size": {
					Description: "Sort buffer size in bytes for ORDER BY optimization. Default is 262144 (256K)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"sql_mode": {
					Description: "Global SQL mode. Set to empty to use MySQL server defaults. When creating a new service and not setting this field Aiven default SQL mode (strict, SQL standard compliant) will be assigned.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"sql_require_primary_key": {
					Description: "Require primary key to be defined for new tables or old tables modified with ALTER TABLE and fail if missing. It is recommended to always have primary keys because various functionality may break if any large table is missing them.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"tmp_table_size": {
					Description: "Limits the size of internal in-memory tables. Also set max_heap_table_size. Default is 16777216 (16M)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"wait_timeout": {
					Description: "The number of seconds the server waits for activity on a noninteractive connection before closing it.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"mysql_version": {
			Description: "MySQL major version",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"private_access": {
			Description: "Allow access to selected service ports from private networks",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"mysql": {
					Description: "Allow clients to connect to mysql with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"mysqlx": {
					Description: "Allow clients to connect to mysqlx with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"mysql": {
					Description: "Allow clients to connect to mysql with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"mysqlx": {
					Description: "Allow clients to connect to mysqlx with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"privatelink_access": {
			Description: "Allow access to selected service components through Privatelink",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"mysql": {
					Description: "Enable mysql",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"mysqlx": {
					Description: "Enable mysqlx",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Enable prometheus",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"mysql": {
					Description: "Enable mysql",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"mysqlx": {
					Description: "Enable mysqlx",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Enable prometheus",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"project_to_fork_from": {
			Description: "Name of another project to fork a service from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"public_access": {
			Description: "Allow access to selected service ports from the public Internet",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"mysql": {
					Description: "Allow clients to connect to mysql from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"mysqlx": {
					Description: "Allow clients to connect to mysqlx from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"mysql": {
					Description: "Allow clients to connect to mysql from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"mysqlx": {
					Description: "Allow clients to connect to mysqlx from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"recovery_target_time": {
			Description: "Recovery target time when forking a service. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"service_to_fork_from": {
			Description: "Name of another service to fork from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"static_ips": {
			Description: "Use static public IP addresses",
			Optional:    true,
			Type:        schema.TypeString,
		},
	}

	return &schema.Schema{
		Description:      "Mysql user configurable settings",
		DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(s),
		Elem:             &schema.Resource{Schema: s},
		MaxItems:         1,
		Optional:         true,
		Type:             schema.TypeList,
	}
}

// ServiceTypeOpensearch is a generated function returning the schema of the opensearch ServiceType.
func ServiceTypeOpensearch() *schema.Schema {
	s := map[string]*schema.Schema{
		"additional_backup_regions": {
			Description: "Additional Cloud Regions for Backup Replication",
			Elem:        &schema.Schema{Type: schema.TypeString},
			MaxItems:    1,
			Optional:    true,
			Type:        schema.TypeList,
		},
		"custom_domain": {
			Description: "Serve the web frontend using a custom CNAME pointing to the Aiven DNS name",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"disable_replication_factor_adjustment": {
			Deprecated: "DEPRECATED: Disable automatic replication factor adjustment for multi-node services. By default, Aiven ensures all indexes are replicated at least to two nodes. Note: Due to potential data loss in case of losing a service node, this setting can no longer be activated.",
			Optional:   true,
			Type:       schema.TypeString,
		},
		"index_patterns": {
			Description: "Index patterns",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"max_index_count": {
					Description: "Maximum number of indexes to keep",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"pattern": {
					Description: "fnmatch pattern",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"sorting_algorithm": {
					Description: "Deletion sorting algorithm",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 512,
			Optional: true,
			Type:     schema.TypeList,
		},
		"index_template": {
			Description: "Template settings for all new indexes",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"mapping_nested_objects_limit": {
					Description: "The maximum number of nested JSON objects that a single document can contain across all nested types. This limit helps to prevent out of memory errors when a document contains too many nested objects. Default is 10000.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"number_of_replicas": {
					Description: "The number of replicas each primary shard has.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"number_of_shards": {
					Description: "The number of primary shards that an index should have.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"mapping_nested_objects_limit": {
					Description: "The maximum number of nested JSON objects that a single document can contain across all nested types. This limit helps to prevent out of memory errors when a document contains too many nested objects. Default is 10000.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"number_of_replicas": {
					Description: "The number of replicas each primary shard has.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"number_of_shards": {
					Description: "The number of primary shards that an index should have.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter": {
			Description:      "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			DiffSuppressFunc: schemautil.IPFilterArrayDiffSuppressFunc,
			Elem: &schema.Schema{
				DiffSuppressFunc: schemautil.IPFilterValueDiffSuppressFunc,
				Type:             schema.TypeString,
			},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter_object": {
			Description: "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"description": {
					Description: "Description for IP filter list entry",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"network": {
					Description: "CIDR address block",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"keep_index_refresh_interval": {
			Description: "Aiven automation resets index.refresh_interval to default value for every index to be sure that indices are always visible to search. If it doesn't fit your case, you can disable this by setting up this flag to true.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"max_index_count": {
			Deprecated: "DEPRECATED: use index_patterns instead",
			Optional:   true,
			Type:       schema.TypeString,
		},
		"opensearch": {
			Description: "OpenSearch settings",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"action_auto_create_index_enabled": {
					Description: "Explicitly allow or block automatic creation of indices. Defaults to true",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"action_destructive_requires_name": {
					Description: "Require explicit index names when deleting",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"cluster_max_shards_per_node": {
					Description: "Controls the number of shards allowed in the cluster per data node",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"cluster_routing_allocation_node_concurrent_recoveries": {
					Description: "How many concurrent incoming/outgoing shard recoveries (normally replicas) are allowed to happen on a node. Defaults to 2.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"email_sender_name": {
					Description: "This should be identical to the Sender name defined in Opensearch dashboards",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"email_sender_password": {
					Description: "Sender email password for Opensearch alerts to authenticate with SMTP server",
					Optional:    true,
					Sensitive:   true,
					Type:        schema.TypeString,
				},
				"email_sender_username": {
					Description: "Sender email address for Opensearch alerts",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"http_max_content_length": {
					Description: "Maximum content length for HTTP requests to the OpenSearch HTTP API, in bytes.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"http_max_header_size": {
					Description: "The max size of allowed headers, in bytes",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"http_max_initial_line_length": {
					Description: "The max length of an HTTP URL, in bytes",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_fielddata_cache_size": {
					Description: "Relative amount. Maximum amount of heap memory used for field data cache. This is an expert setting; decreasing the value too much will increase overhead of loading field data; too much memory used for field data cache will decrease amount of heap available for other operations.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_memory_index_buffer_size": {
					Description: "Percentage value. Default is 10%. Total amount of heap used for indexing buffer, before writing segments to disk. This is an expert setting. Too low value will slow down indexing; too high value will increase indexing performance but causes performance issues for query performance.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_queries_cache_size": {
					Description: "Percentage value. Default is 10%. Maximum amount of heap used for query cache. This is an expert setting. Too low value will decrease query performance and increase performance for other operations; too high value will cause issues with other OpenSearch functionality.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_query_bool_max_clause_count": {
					Description: "Maximum number of clauses Lucene BooleanQuery can have. The default value (1024) is relatively high, and increasing it may cause performance issues. Investigate other approaches first before increasing this value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_recovery_max_bytes_per_sec": {
					Description: "Limits total inbound and outbound recovery traffic for each node. Applies to both peer recoveries as well as snapshot recoveries (i.e., restores from a snapshot). Defaults to 40mb",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_recovery_max_concurrent_file_chunks": {
					Description: "Number of file chunks sent in parallel for each recovery. Defaults to 2.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"override_main_response_version": {
					Description: "Compatibility mode sets OpenSearch to report its version as 7.10 so clients continue to work. Default is false",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"reindex_remote_whitelist": {
					Description: "Whitelisted addresses for reindexing. Changing this value will cause all OpenSearch instances to restart.",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    32,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"script_max_compilations_rate": {
					Description: "Script compilation circuit breaker limits the number of inline script compilations within a period of time. Default is use-context",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"search_max_buckets": {
					Description: "Maximum number of aggregation buckets allowed in a single response. OpenSearch default value is used when this is not defined.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_analyze_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_analyze_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_force_merge_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_get_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_get_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_search_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_search_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_search_throttled_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_search_throttled_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_write_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_write_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"action_auto_create_index_enabled": {
					Description: "Explicitly allow or block automatic creation of indices. Defaults to true",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"action_destructive_requires_name": {
					Description: "Require explicit index names when deleting",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"cluster_max_shards_per_node": {
					Description: "Controls the number of shards allowed in the cluster per data node",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"cluster_routing_allocation_node_concurrent_recoveries": {
					Description: "How many concurrent incoming/outgoing shard recoveries (normally replicas) are allowed to happen on a node. Defaults to 2.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"email_sender_name": {
					Description: "This should be identical to the Sender name defined in Opensearch dashboards",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"email_sender_password": {
					Description: "Sender email password for Opensearch alerts to authenticate with SMTP server",
					Optional:    true,
					Sensitive:   true,
					Type:        schema.TypeString,
				},
				"email_sender_username": {
					Description: "Sender email address for Opensearch alerts",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"http_max_content_length": {
					Description: "Maximum content length for HTTP requests to the OpenSearch HTTP API, in bytes.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"http_max_header_size": {
					Description: "The max size of allowed headers, in bytes",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"http_max_initial_line_length": {
					Description: "The max length of an HTTP URL, in bytes",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_fielddata_cache_size": {
					Description: "Relative amount. Maximum amount of heap memory used for field data cache. This is an expert setting; decreasing the value too much will increase overhead of loading field data; too much memory used for field data cache will decrease amount of heap available for other operations.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_memory_index_buffer_size": {
					Description: "Percentage value. Default is 10%. Total amount of heap used for indexing buffer, before writing segments to disk. This is an expert setting. Too low value will slow down indexing; too high value will increase indexing performance but causes performance issues for query performance.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_queries_cache_size": {
					Description: "Percentage value. Default is 10%. Maximum amount of heap used for query cache. This is an expert setting. Too low value will decrease query performance and increase performance for other operations; too high value will cause issues with other OpenSearch functionality.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_query_bool_max_clause_count": {
					Description: "Maximum number of clauses Lucene BooleanQuery can have. The default value (1024) is relatively high, and increasing it may cause performance issues. Investigate other approaches first before increasing this value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_recovery_max_bytes_per_sec": {
					Description: "Limits total inbound and outbound recovery traffic for each node. Applies to both peer recoveries as well as snapshot recoveries (i.e., restores from a snapshot). Defaults to 40mb",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"indices_recovery_max_concurrent_file_chunks": {
					Description: "Number of file chunks sent in parallel for each recovery. Defaults to 2.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"override_main_response_version": {
					Description: "Compatibility mode sets OpenSearch to report its version as 7.10 so clients continue to work. Default is false",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"reindex_remote_whitelist": {
					Description: "Whitelisted addresses for reindexing. Changing this value will cause all OpenSearch instances to restart.",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    32,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"script_max_compilations_rate": {
					Description: "Script compilation circuit breaker limits the number of inline script compilations within a period of time. Default is use-context",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"search_max_buckets": {
					Description: "Maximum number of aggregation buckets allowed in a single response. OpenSearch default value is used when this is not defined.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_analyze_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_analyze_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_force_merge_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_get_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_get_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_search_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_search_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_search_throttled_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_search_throttled_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_write_queue_size": {
					Description: "Size for the thread pool queue. See documentation for exact details.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"thread_pool_write_size": {
					Description: "Size for the thread pool. See documentation for exact details. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"opensearch_dashboards": {
			Description: "OpenSearch Dashboards settings",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"enabled": {
					Description: "Enable or disable OpenSearch Dashboards",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_old_space_size": {
					Description: "Limits the maximum amount of memory (in MiB) the OpenSearch Dashboards process can use. This sets the max_old_space_size option of the nodejs running the OpenSearch Dashboards. Note: the memory reserved by OpenSearch Dashboards is not available for OpenSearch.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"opensearch_request_timeout": {
					Description: "Timeout in milliseconds for requests made by OpenSearch Dashboards towards OpenSearch",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"enabled": {
					Description: "Enable or disable OpenSearch Dashboards",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_old_space_size": {
					Description: "Limits the maximum amount of memory (in MiB) the OpenSearch Dashboards process can use. This sets the max_old_space_size option of the nodejs running the OpenSearch Dashboards. Note: the memory reserved by OpenSearch Dashboards is not available for OpenSearch.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"opensearch_request_timeout": {
					Description: "Timeout in milliseconds for requests made by OpenSearch Dashboards towards OpenSearch",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"opensearch_version": {
			Description: "OpenSearch major version",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"private_access": {
			Description: "Allow access to selected service ports from private networks",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"opensearch": {
					Description: "Allow clients to connect to opensearch with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"opensearch_dashboards": {
					Description: "Allow clients to connect to opensearch_dashboards with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"opensearch": {
					Description: "Allow clients to connect to opensearch with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"opensearch_dashboards": {
					Description: "Allow clients to connect to opensearch_dashboards with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"privatelink_access": {
			Description: "Allow access to selected service components through Privatelink",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"opensearch": {
					Description: "Enable opensearch",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"opensearch_dashboards": {
					Description: "Enable opensearch_dashboards",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Enable prometheus",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"opensearch": {
					Description: "Enable opensearch",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"opensearch_dashboards": {
					Description: "Enable opensearch_dashboards",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Enable prometheus",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"project_to_fork_from": {
			Description: "Name of another project to fork a service from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"public_access": {
			Description: "Allow access to selected service ports from the public Internet",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"opensearch": {
					Description: "Allow clients to connect to opensearch from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"opensearch_dashboards": {
					Description: "Allow clients to connect to opensearch_dashboards from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"opensearch": {
					Description: "Allow clients to connect to opensearch from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"opensearch_dashboards": {
					Description: "Allow clients to connect to opensearch_dashboards from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"recovery_basebackup_name": {
			Description: "Name of the basebackup to restore in forked service",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"service_to_fork_from": {
			Description: "Name of another service to fork from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"static_ips": {
			Description: "Use static public IP addresses",
			Optional:    true,
			Type:        schema.TypeString,
		},
	}

	return &schema.Schema{
		Description:      "Opensearch user configurable settings",
		DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(s),
		Elem:             &schema.Resource{Schema: s},
		MaxItems:         1,
		Optional:         true,
		Type:             schema.TypeList,
	}
}

// ServiceTypePg is a generated function returning the schema of the pg ServiceType.
func ServiceTypePg() *schema.Schema {
	s := map[string]*schema.Schema{
		"additional_backup_regions": {
			Description: "Additional Cloud Regions for Backup Replication",
			Elem:        &schema.Schema{Type: schema.TypeString},
			MaxItems:    1,
			Optional:    true,
			Type:        schema.TypeList,
		},
		"admin_password": {
			Description: "Custom password for admin user. Defaults to random string. This must be set only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Sensitive:   true,
			Type:        schema.TypeString,
		},
		"admin_username": {
			Description: "Custom username for admin user. This must be set only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"backup_hour": {
			Description: "The hour of day (in UTC) when backup for the service is started. New backup is only started if previous backup has already completed.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"backup_minute": {
			Description: "The minute of an hour when backup for the service is started. New backup is only started if previous backup has already completed.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"enable_ipv6": {
			Description: "Register AAAA DNS records for the service, and allow IPv6 packets to service ports",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"ip_filter": {
			Description:      "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			DiffSuppressFunc: schemautil.IPFilterArrayDiffSuppressFunc,
			Elem: &schema.Schema{
				DiffSuppressFunc: schemautil.IPFilterValueDiffSuppressFunc,
				Type:             schema.TypeString,
			},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter_object": {
			Description: "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"description": {
					Description: "Description for IP filter list entry",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"network": {
					Description: "CIDR address block",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"migration": {
			Description: "Migrate data from existing server",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"dbname": {
					Description: "Database name for bootstrapping the initial connection",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"host": {
					Description: "Hostname or IP address of the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"ignore_dbs": {
					Description: "Comma-separated list of databases, which should be ignored during migration (supported by MySQL only at the moment)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"method": {
					Description: "The migration method to be used (currently supported only by Redis and MySQL service types)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"password": {
					Description: "Password for authentication with the server where to migrate data from",
					Optional:    true,
					Sensitive:   true,
					Type:        schema.TypeString,
				},
				"port": {
					Description: "Port number of the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"ssl": {
					Description: "The server where to migrate data from is secured with SSL",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"username": {
					Description: "User name for authentication with the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"dbname": {
					Description: "Database name for bootstrapping the initial connection",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"host": {
					Description: "Hostname or IP address of the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"ignore_dbs": {
					Description: "Comma-separated list of databases, which should be ignored during migration (supported by MySQL only at the moment)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"method": {
					Description: "The migration method to be used (currently supported only by Redis and MySQL service types)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"password": {
					Description: "Password for authentication with the server where to migrate data from",
					Optional:    true,
					Sensitive:   true,
					Type:        schema.TypeString,
				},
				"port": {
					Description: "Port number of the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"ssl": {
					Description: "The server where to migrate data from is secured with SSL",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"username": {
					Description: "User name for authentication with the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"pg": {
			Description: "postgresql.conf configuration values",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"autovacuum_analyze_scale_factor": {
					Description: "Specifies a fraction of the table size to add to autovacuum_analyze_threshold when deciding whether to trigger an ANALYZE. The default is 0.2 (20% of table size)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autovacuum_analyze_threshold": {
					Description: "Specifies the minimum number of inserted, updated or deleted tuples needed to trigger an  ANALYZE in any one table. The default is 50 tuples.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autovacuum_freeze_max_age": {
					Description: "Specifies the maximum age (in transactions) that a table's pg_class.relfrozenxid field can attain before a VACUUM operation is forced to prevent transaction ID wraparound within the table. Note that the system will launch autovacuum processes to prevent wraparound even when autovacuum is otherwise disabled. This parameter will cause the server to be restarted.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autovacuum_max_workers": {
					Description: "Specifies the maximum number of autovacuum processes (other than the autovacuum launcher) that may be running at any one time. The default is three. This parameter can only be set at server start.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autovacuum_naptime": {
					Description: "Specifies the minimum delay between autovacuum runs on any given database. The delay is measured in seconds, and the default is one minute",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autovacuum_vacuum_cost_delay": {
					Description: "Specifies the cost delay value that will be used in automatic VACUUM operations. If -1 is specified, the regular vacuum_cost_delay value will be used. The default value is 20 milliseconds",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autovacuum_vacuum_cost_limit": {
					Description: "Specifies the cost limit value that will be used in automatic VACUUM operations. If -1 is specified (which is the default), the regular vacuum_cost_limit value will be used.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autovacuum_vacuum_scale_factor": {
					Description: "Specifies a fraction of the table size to add to autovacuum_vacuum_threshold when deciding whether to trigger a VACUUM. The default is 0.2 (20% of table size)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autovacuum_vacuum_threshold": {
					Description: "Specifies the minimum number of updated or deleted tuples needed to trigger a VACUUM in any one table. The default is 50 tuples",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"bgwriter_delay": {
					Description: "Specifies the delay between activity rounds for the background writer in milliseconds. Default is 200.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"bgwriter_flush_after": {
					Description: "Whenever more than bgwriter_flush_after bytes have been written by the background writer, attempt to force the OS to issue these writes to the underlying storage. Specified in kilobytes, default is 512. Setting of 0 disables forced writeback.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"bgwriter_lru_maxpages": {
					Description: "In each round, no more than this many buffers will be written by the background writer. Setting this to zero disables background writing. Default is 100.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"bgwriter_lru_multiplier": {
					Description: "The average recent need for new buffers is multiplied by bgwriter_lru_multiplier to arrive at an estimate of the number that will be needed during the next round, (up to bgwriter_lru_maxpages). 1.0 represents a “just in time” policy of writing exactly the number of buffers predicted to be needed. Larger values provide some cushion against spikes in demand, while smaller values intentionally leave writes to be done by server processes. The default is 2.0.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"deadlock_timeout": {
					Description: "This is the amount of time, in milliseconds, to wait on a lock before checking to see if there is a deadlock condition.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"default_toast_compression": {
					Description: "Specifies the default TOAST compression method for values of compressible columns (the default is lz4).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"idle_in_transaction_session_timeout": {
					Description: "Time out sessions with open transactions after this number of milliseconds",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"jit": {
					Description: "Controls system-wide use of Just-in-Time Compilation (JIT).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_autovacuum_min_duration": {
					Description: "Causes each action executed by autovacuum to be logged if it ran for at least the specified number of milliseconds. Setting this to zero logs all autovacuum actions. Minus-one (the default) disables logging autovacuum actions.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_error_verbosity": {
					Description: "Controls the amount of detail written in the server log for each message that is logged.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_line_prefix": {
					Description: "Choose from one of the available log-formats. These can support popular log analyzers like pgbadger, pganalyze etc.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_min_duration_statement": {
					Description: "Log statements that take more than this number of milliseconds to run, -1 disables",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_temp_files": {
					Description: "Log statements for each temporary file created larger than this number of kilobytes, -1 disables",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_files_per_process": {
					Description: "PostgreSQL maximum number of files that can be open per process",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_locks_per_transaction": {
					Description: "PostgreSQL maximum locks per transaction",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_logical_replication_workers": {
					Description: "PostgreSQL maximum logical replication workers (taken from the pool of max_parallel_workers)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_parallel_workers": {
					Description: "Sets the maximum number of workers that the system can support for parallel queries",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_parallel_workers_per_gather": {
					Description: "Sets the maximum number of workers that can be started by a single Gather or Gather Merge node",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_pred_locks_per_transaction": {
					Description: "PostgreSQL maximum predicate locks per transaction",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_prepared_transactions": {
					Description: "PostgreSQL maximum prepared transactions",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_replication_slots": {
					Description: "PostgreSQL maximum replication slots",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_slot_wal_keep_size": {
					Description: "PostgreSQL maximum WAL size (MB) reserved for replication slots. Default is -1 (unlimited). wal_keep_size minimum WAL size setting takes precedence over this.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_stack_depth": {
					Description: "Maximum depth of the stack in bytes",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_standby_archive_delay": {
					Description: "Max standby archive delay in milliseconds",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_standby_streaming_delay": {
					Description: "Max standby streaming delay in milliseconds",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_wal_senders": {
					Description: "PostgreSQL maximum WAL senders",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_worker_processes": {
					Description: "Sets the maximum number of background processes that the system can support",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"pg_partman_bgw__dot__interval": {
					Description: "Sets the time interval to run pg_partman's scheduled tasks",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"pg_partman_bgw__dot__role": {
					Description: "Controls which role to use for pg_partman's scheduled background tasks.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"pg_stat_statements__dot__track": {
					Description: "Controls which statements are counted. Specify top to track top-level statements (those issued directly by clients), all to also track nested statements (such as statements invoked within functions), or none to disable statement statistics collection. The default value is top.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"temp_file_limit": {
					Description: "PostgreSQL temporary file limit in KiB, -1 for unlimited",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"timezone": {
					Description: "PostgreSQL service timezone",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"track_activity_query_size": {
					Description: "Specifies the number of bytes reserved to track the currently executing command for each active session.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"track_commit_timestamp": {
					Description: "Record commit time of transactions.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"track_functions": {
					Description: "Enables tracking of function call counts and time used.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"track_io_timing": {
					Description: "Enables timing of database I/O calls. This parameter is off by default, because it will repeatedly query the operating system for the current time, which may cause significant overhead on some platforms.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"wal_sender_timeout": {
					Description: "Terminate replication connections that are inactive for longer than this amount of time, in milliseconds. Setting this value to zero disables the timeout.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"wal_writer_delay": {
					Description: "WAL flush interval in milliseconds. Note that setting this value to lower than the default 200ms may negatively impact performance",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"autovacuum_analyze_scale_factor": {
					Description: "Specifies a fraction of the table size to add to autovacuum_analyze_threshold when deciding whether to trigger an ANALYZE. The default is 0.2 (20% of table size)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autovacuum_analyze_threshold": {
					Description: "Specifies the minimum number of inserted, updated or deleted tuples needed to trigger an  ANALYZE in any one table. The default is 50 tuples.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autovacuum_freeze_max_age": {
					Description: "Specifies the maximum age (in transactions) that a table's pg_class.relfrozenxid field can attain before a VACUUM operation is forced to prevent transaction ID wraparound within the table. Note that the system will launch autovacuum processes to prevent wraparound even when autovacuum is otherwise disabled. This parameter will cause the server to be restarted.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autovacuum_max_workers": {
					Description: "Specifies the maximum number of autovacuum processes (other than the autovacuum launcher) that may be running at any one time. The default is three. This parameter can only be set at server start.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autovacuum_naptime": {
					Description: "Specifies the minimum delay between autovacuum runs on any given database. The delay is measured in seconds, and the default is one minute",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autovacuum_vacuum_cost_delay": {
					Description: "Specifies the cost delay value that will be used in automatic VACUUM operations. If -1 is specified, the regular vacuum_cost_delay value will be used. The default value is 20 milliseconds",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autovacuum_vacuum_cost_limit": {
					Description: "Specifies the cost limit value that will be used in automatic VACUUM operations. If -1 is specified (which is the default), the regular vacuum_cost_limit value will be used.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autovacuum_vacuum_scale_factor": {
					Description: "Specifies a fraction of the table size to add to autovacuum_vacuum_threshold when deciding whether to trigger a VACUUM. The default is 0.2 (20% of table size)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autovacuum_vacuum_threshold": {
					Description: "Specifies the minimum number of updated or deleted tuples needed to trigger a VACUUM in any one table. The default is 50 tuples",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"bgwriter_delay": {
					Description: "Specifies the delay between activity rounds for the background writer in milliseconds. Default is 200.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"bgwriter_flush_after": {
					Description: "Whenever more than bgwriter_flush_after bytes have been written by the background writer, attempt to force the OS to issue these writes to the underlying storage. Specified in kilobytes, default is 512. Setting of 0 disables forced writeback.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"bgwriter_lru_maxpages": {
					Description: "In each round, no more than this many buffers will be written by the background writer. Setting this to zero disables background writing. Default is 100.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"bgwriter_lru_multiplier": {
					Description: "The average recent need for new buffers is multiplied by bgwriter_lru_multiplier to arrive at an estimate of the number that will be needed during the next round, (up to bgwriter_lru_maxpages). 1.0 represents a “just in time” policy of writing exactly the number of buffers predicted to be needed. Larger values provide some cushion against spikes in demand, while smaller values intentionally leave writes to be done by server processes. The default is 2.0.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"deadlock_timeout": {
					Description: "This is the amount of time, in milliseconds, to wait on a lock before checking to see if there is a deadlock condition.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"default_toast_compression": {
					Description: "Specifies the default TOAST compression method for values of compressible columns (the default is lz4).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"idle_in_transaction_session_timeout": {
					Description: "Time out sessions with open transactions after this number of milliseconds",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"jit": {
					Description: "Controls system-wide use of Just-in-Time Compilation (JIT).",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_autovacuum_min_duration": {
					Description: "Causes each action executed by autovacuum to be logged if it ran for at least the specified number of milliseconds. Setting this to zero logs all autovacuum actions. Minus-one (the default) disables logging autovacuum actions.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_error_verbosity": {
					Description: "Controls the amount of detail written in the server log for each message that is logged.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_line_prefix": {
					Description: "Choose from one of the available log-formats. These can support popular log analyzers like pgbadger, pganalyze etc.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_min_duration_statement": {
					Description: "Log statements that take more than this number of milliseconds to run, -1 disables",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"log_temp_files": {
					Description: "Log statements for each temporary file created larger than this number of kilobytes, -1 disables",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_files_per_process": {
					Description: "PostgreSQL maximum number of files that can be open per process",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_locks_per_transaction": {
					Description: "PostgreSQL maximum locks per transaction",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_logical_replication_workers": {
					Description: "PostgreSQL maximum logical replication workers (taken from the pool of max_parallel_workers)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_parallel_workers": {
					Description: "Sets the maximum number of workers that the system can support for parallel queries",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_parallel_workers_per_gather": {
					Description: "Sets the maximum number of workers that can be started by a single Gather or Gather Merge node",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_pred_locks_per_transaction": {
					Description: "PostgreSQL maximum predicate locks per transaction",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_prepared_transactions": {
					Description: "PostgreSQL maximum prepared transactions",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_replication_slots": {
					Description: "PostgreSQL maximum replication slots",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_slot_wal_keep_size": {
					Description: "PostgreSQL maximum WAL size (MB) reserved for replication slots. Default is -1 (unlimited). wal_keep_size minimum WAL size setting takes precedence over this.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_stack_depth": {
					Description: "Maximum depth of the stack in bytes",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_standby_archive_delay": {
					Description: "Max standby archive delay in milliseconds",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_standby_streaming_delay": {
					Description: "Max standby streaming delay in milliseconds",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_wal_senders": {
					Description: "PostgreSQL maximum WAL senders",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"max_worker_processes": {
					Description: "Sets the maximum number of background processes that the system can support",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"pg_partman_bgw__dot__interval": {
					Description: "Sets the time interval to run pg_partman's scheduled tasks",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"pg_partman_bgw__dot__role": {
					Description: "Controls which role to use for pg_partman's scheduled background tasks.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"pg_stat_statements__dot__track": {
					Description: "Controls which statements are counted. Specify top to track top-level statements (those issued directly by clients), all to also track nested statements (such as statements invoked within functions), or none to disable statement statistics collection. The default value is top.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"temp_file_limit": {
					Description: "PostgreSQL temporary file limit in KiB, -1 for unlimited",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"timezone": {
					Description: "PostgreSQL service timezone",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"track_activity_query_size": {
					Description: "Specifies the number of bytes reserved to track the currently executing command for each active session.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"track_commit_timestamp": {
					Description: "Record commit time of transactions.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"track_functions": {
					Description: "Enables tracking of function call counts and time used.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"track_io_timing": {
					Description: "Enables timing of database I/O calls. This parameter is off by default, because it will repeatedly query the operating system for the current time, which may cause significant overhead on some platforms.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"wal_sender_timeout": {
					Description: "Terminate replication connections that are inactive for longer than this amount of time, in milliseconds. Setting this value to zero disables the timeout.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"wal_writer_delay": {
					Description: "WAL flush interval in milliseconds. Note that setting this value to lower than the default 200ms may negatively impact performance",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"pg_read_replica": {
			Deprecated: "This setting is deprecated. Use read_replica service integration instead.",
			Optional:   true,
			Type:       schema.TypeString,
		},
		"pg_service_to_fork_from": {
			Description: "Name of the PG Service from which to fork (deprecated, use service_to_fork_from). This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"pg_stat_monitor_enable": {
			Description: "Enable the pg_stat_monitor extension. Enabling this extension will cause the cluster to be restarted.When this extension is enabled, pg_stat_statements results for utility commands are unreliable",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"pg_version": {
			Description: "PostgreSQL major version",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"pgbouncer": {
			Description: "PGBouncer connection pooling settings",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"autodb_idle_timeout": {
					Description: "If the automatically created database pools have been unused this many seconds, they are freed. If 0 then timeout is disabled. [seconds]",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autodb_max_db_connections": {
					Description: "Do not allow more than this many server connections per database (regardless of user). Setting it to 0 means unlimited.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autodb_pool_mode": {
					Description: "PGBouncer pool mode",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autodb_pool_size": {
					Description: "If non-zero then create automatically a pool of that size per user when a pool doesn't exist.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"ignore_startup_parameters": {
					Description: "List of parameters to ignore when given in startup packet",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    32,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"min_pool_size": {
					Description: "Add more server connections to pool if below this number. Improves behavior when usual load comes suddenly back after period of total inactivity. The value is effectively capped at the pool size.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"server_idle_timeout": {
					Description: "If a server connection has been idle more than this many seconds it will be dropped. If 0 then timeout is disabled. [seconds]",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"server_lifetime": {
					Description: "The pooler will close an unused server connection that has been connected longer than this. [seconds]",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"server_reset_query_always": {
					Description: "Run server_reset_query (DISCARD ALL) in all pooling modes",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"autodb_idle_timeout": {
					Description: "If the automatically created database pools have been unused this many seconds, they are freed. If 0 then timeout is disabled. [seconds]",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autodb_max_db_connections": {
					Description: "Do not allow more than this many server connections per database (regardless of user). Setting it to 0 means unlimited.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autodb_pool_mode": {
					Description: "PGBouncer pool mode",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"autodb_pool_size": {
					Description: "If non-zero then create automatically a pool of that size per user when a pool doesn't exist.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"ignore_startup_parameters": {
					Description: "List of parameters to ignore when given in startup packet",
					Elem:        &schema.Schema{Type: schema.TypeString},
					MaxItems:    32,
					Optional:    true,
					Type:        schema.TypeList,
				},
				"min_pool_size": {
					Description: "Add more server connections to pool if below this number. Improves behavior when usual load comes suddenly back after period of total inactivity. The value is effectively capped at the pool size.",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"server_idle_timeout": {
					Description: "If a server connection has been idle more than this many seconds it will be dropped. If 0 then timeout is disabled. [seconds]",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"server_lifetime": {
					Description: "The pooler will close an unused server connection that has been connected longer than this. [seconds]",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"server_reset_query_always": {
					Description: "Run server_reset_query (DISCARD ALL) in all pooling modes",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"pglookout": {
			Description: "PGLookout settings",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{"max_failover_replication_time_lag": {
				Description: "Number of seconds of master unavailability before triggering database failover to standby",
				Optional:    true,
				Type:        schema.TypeString,
			}}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{"max_failover_replication_time_lag": {
				Description: "Number of seconds of master unavailability before triggering database failover to standby",
				Optional:    true,
				Type:        schema.TypeString,
			}}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"private_access": {
			Description: "Allow access to selected service ports from private networks",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"pg": {
					Description: "Allow clients to connect to pg with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"pgbouncer": {
					Description: "Allow clients to connect to pgbouncer with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"pg": {
					Description: "Allow clients to connect to pg with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"pgbouncer": {
					Description: "Allow clients to connect to pgbouncer with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"privatelink_access": {
			Description: "Allow access to selected service components through Privatelink",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"pg": {
					Description: "Enable pg",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"pgbouncer": {
					Description: "Enable pgbouncer",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Enable prometheus",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"pg": {
					Description: "Enable pg",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"pgbouncer": {
					Description: "Enable pgbouncer",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Enable prometheus",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"project_to_fork_from": {
			Description: "Name of another project to fork a service from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"public_access": {
			Description: "Allow access to selected service ports from the public Internet",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"pg": {
					Description: "Allow clients to connect to pg from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"pgbouncer": {
					Description: "Allow clients to connect to pgbouncer from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"pg": {
					Description: "Allow clients to connect to pg from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"pgbouncer": {
					Description: "Allow clients to connect to pgbouncer from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"prometheus": {
					Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"recovery_target_time": {
			Description: "Recovery target time when forking a service. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"service_to_fork_from": {
			Description: "Name of another service to fork from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"shared_buffers_percentage": {
			Description: "Percentage of total RAM that the database server uses for shared memory buffers. Valid range is 20-60 (float), which corresponds to 20% - 60%. This setting adjusts the shared_buffers configuration value.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"static_ips": {
			Description: "Use static public IP addresses",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"synchronous_replication": {
			Description: "Synchronous replication type. Note that the service plan also needs to support synchronous replication.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"timescaledb": {
			Description: "TimescaleDB extension configuration values",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{"max_background_workers": {
				Description: "The number of background workers for timescaledb operations. You should configure this setting to the sum of your number of databases and the total number of concurrent background workers you want running at any given point in time.",
				Optional:    true,
				Type:        schema.TypeString,
			}}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{"max_background_workers": {
				Description: "The number of background workers for timescaledb operations. You should configure this setting to the sum of your number of databases and the total number of concurrent background workers you want running at any given point in time.",
				Optional:    true,
				Type:        schema.TypeString,
			}}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"variant": {
			Description: "Variant of the PostgreSQL service, may affect the features that are exposed by default",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"work_mem": {
			Description: "Sets the maximum amount of memory to be used by a query operation (such as a sort or hash table) before writing to temporary disk files, in MB. Default is 1MB + 0.075% of total RAM (up to 32MB).",
			Optional:    true,
			Type:        schema.TypeString,
		},
	}

	return &schema.Schema{
		Description:      "Pg user configurable settings",
		DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(s),
		Elem:             &schema.Resource{Schema: s},
		MaxItems:         1,
		Optional:         true,
		Type:             schema.TypeList,
	}
}

// ServiceTypeRedis is a generated function returning the schema of the redis ServiceType.
func ServiceTypeRedis() *schema.Schema {
	s := map[string]*schema.Schema{
		"additional_backup_regions": {
			Description: "Additional Cloud Regions for Backup Replication",
			Elem:        &schema.Schema{Type: schema.TypeString},
			MaxItems:    1,
			Optional:    true,
			Type:        schema.TypeList,
		},
		"ip_filter": {
			Description:      "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			DiffSuppressFunc: schemautil.IPFilterArrayDiffSuppressFunc,
			Elem: &schema.Schema{
				DiffSuppressFunc: schemautil.IPFilterValueDiffSuppressFunc,
				Type:             schema.TypeString,
			},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"ip_filter_object": {
			Description: "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"description": {
					Description: "Description for IP filter list entry",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"network": {
					Description: "CIDR address block",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1024,
			Optional: true,
			Type:     schema.TypeList,
		},
		"migration": {
			Description: "Migrate data from existing server",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"dbname": {
					Description: "Database name for bootstrapping the initial connection",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"host": {
					Description: "Hostname or IP address of the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"ignore_dbs": {
					Description: "Comma-separated list of databases, which should be ignored during migration (supported by MySQL only at the moment)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"method": {
					Description: "The migration method to be used (currently supported only by Redis and MySQL service types)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"password": {
					Description: "Password for authentication with the server where to migrate data from",
					Optional:    true,
					Sensitive:   true,
					Type:        schema.TypeString,
				},
				"port": {
					Description: "Port number of the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"ssl": {
					Description: "The server where to migrate data from is secured with SSL",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"username": {
					Description: "User name for authentication with the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"dbname": {
					Description: "Database name for bootstrapping the initial connection",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"host": {
					Description: "Hostname or IP address of the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"ignore_dbs": {
					Description: "Comma-separated list of databases, which should be ignored during migration (supported by MySQL only at the moment)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"method": {
					Description: "The migration method to be used (currently supported only by Redis and MySQL service types)",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"password": {
					Description: "Password for authentication with the server where to migrate data from",
					Optional:    true,
					Sensitive:   true,
					Type:        schema.TypeString,
				},
				"port": {
					Description: "Port number of the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"ssl": {
					Description: "The server where to migrate data from is secured with SSL",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"username": {
					Description: "User name for authentication with the server where to migrate data from",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"private_access": {
			Description: "Allow access to selected service ports from private networks",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"prometheus": {
					Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"redis": {
					Description: "Allow clients to connect to redis with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"prometheus": {
					Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"redis": {
					Description: "Allow clients to connect to redis with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"privatelink_access": {
			Description: "Allow access to selected service components through Privatelink",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"prometheus": {
					Description: "Enable prometheus",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"redis": {
					Description: "Enable redis",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"prometheus": {
					Description: "Enable prometheus",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"redis": {
					Description: "Enable redis",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"project_to_fork_from": {
			Description: "Name of another project to fork a service from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"public_access": {
			Description: "Allow access to selected service ports from the public Internet",
			DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(map[string]*schema.Schema{
				"prometheus": {
					Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"redis": {
					Description: "Allow clients to connect to redis from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}),
			Elem: &schema.Resource{Schema: map[string]*schema.Schema{
				"prometheus": {
					Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
				"redis": {
					Description: "Allow clients to connect to redis from the public internet for service nodes that are in a project VPC or another type of private network",
					Optional:    true,
					Type:        schema.TypeString,
				},
			}},
			MaxItems: 1,
			Optional: true,
			Type:     schema.TypeList,
		},
		"recovery_basebackup_name": {
			Description: "Name of the basebackup to restore in forked service",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"redis_acl_channels_default": {
			Description: "Determines default pub/sub channels' ACL for new users if ACL is not supplied. When this option is not defined, all_channels is assumed to keep backward compatibility. This option doesn't affect Redis configuration acl-pubsub-default.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"redis_io_threads": {
			Description: "Redis IO thread count",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"redis_lfu_decay_time": {
			Description: "LFU maxmemory-policy counter decay time in minutes",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"redis_lfu_log_factor": {
			Description: "Counter logarithm factor for volatile-lfu and allkeys-lfu maxmemory-policies",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"redis_maxmemory_policy": {
			Description: "Redis maxmemory-policy",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"redis_notify_keyspace_events": {
			Description: "Set notify-keyspace-events option",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"redis_number_of_databases": {
			Description: "Set number of redis databases. Changing this will cause a restart of redis service.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"redis_persistence": {
			Description: "When persistence is 'rdb', Redis does RDB dumps each 10 minutes if any key is changed. Also RDB dumps are done according to backup schedule for backup purposes. When persistence is 'off', no RDB dumps and backups are done, so data can be lost at any moment if service is restarted for any reason, or if service is powered off. Also service can't be forked.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"redis_pubsub_client_output_buffer_limit": {
			Description: "Set output buffer limit for pub / sub clients in MB. The value is the hard limit, the soft limit is 1/4 of the hard limit. When setting the limit, be mindful of the available memory in the selected service plan.",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"redis_ssl": {
			Description: "Require SSL to access Redis",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"redis_timeout": {
			Description: "Redis idle connection timeout in seconds",
			Optional:    true,
			Type:        schema.TypeString,
		},
		"service_to_fork_from": {
			Description: "Name of another service to fork from. This has effect only when a new service is being created.",
			ForceNew:    true,
			Optional:    true,
			Type:        schema.TypeString,
		},
		"static_ips": {
			Description: "Use static public IP addresses",
			Optional:    true,
			Type:        schema.TypeString,
		},
	}

	return &schema.Schema{
		Description:      "Redis user configurable settings",
		DiffSuppressFunc: schemautil.EmptyObjectDiffSuppressFuncSkipArrays(s),
		Elem:             &schema.Resource{Schema: s},
		MaxItems:         1,
		Optional:         true,
		Type:             schema.TypeList,
	}
}
